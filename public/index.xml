<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>LIU Yue&#39;s blogs</title>
    <link>https://yliuhz.github.io/blogs/</link>
    <description>Recent content on LIU Yue&#39;s blogs</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Mon, 10 Jul 2023 14:47:33 +0800</lastBuildDate><atom:link href="https://yliuhz.github.io/blogs/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Attention Mechanism</title>
      <link>https://yliuhz.github.io/blogs/posts/visofattention/</link>
      <pubDate>Mon, 10 Jul 2023 14:47:33 +0800</pubDate>
      
      <guid>https://yliuhz.github.io/blogs/posts/visofattention/</guid>
      <description>Attention机制 根据OpenAI工程师Andrej Karpathy的讲解视频梳理Attention机制及其在GPT（Generative Pretrained Transformer）语言模型中的应用。在构建GPT的过程中我们会了解到attention的定义和它的工作原理。
构建一个小型GPT模型 GPT属于因果语言模型（Causal Language Models, CLM）。它的任务是根据当前单词（token）预测下一个单词，是自然的无监督任务。比如，现在我们有一个莎士比亚的文本数据：
1 2 3 4 5 6 7 8 First Citizen: Before we proceed any further, hear me speak. All: Speak, speak. First Citizen: You are all resolved rather to die than to famish? 它是由字符组成的，我们需要一个映射，将其转化为模型可接受的数字向量的输入格式。首先将句子进行分词，然后建立词表，再将每个单词映射到词表的索引。这样，我们可以构建GPT的dataloader：对于给定超参数batch_size=$B$，同时给定句子片段长度$T$，dataloader可以定义为从数据中随机采样$B$个连续的长度为$T$的句子片段，来得到一个batch的数据。如下图所示。
接着定义模型架构。这里采用经典的Transformer架构 ( Citation: Vaswani,&amp;#32;Shazeer &amp;amp; al.,&amp;#32;2017 Vaswani,&amp;#32; A.,&amp;#32; Shazeer,&amp;#32; N.,&amp;#32; Parmar,&amp;#32; N.,&amp;#32; Uszkoreit,&amp;#32; J.,&amp;#32; Jones,&amp;#32; L.,&amp;#32; Gomez,&amp;#32; A.,&amp;#32; Kaiser,&amp;#32; L.&amp;#32;&amp;amp;&amp;#32;Polosukhin,&amp;#32; I. &amp;#32; (2017). &amp;#32;Attention Is All You Need.</description>
      <content:encoded><![CDATA[<h2 id="attention机制">Attention机制</h2>
<p>根据OpenAI工程师<a href="https://karpathy.ai/">Andrej Karpathy</a>的<a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&amp;t=4185s">讲解视频</a>梳理Attention机制及其在GPT（Generative Pretrained Transformer）语言模型中的应用。在构建GPT的过程中我们会了解到attention的定义和它的工作原理。</p>
<h3 id="构建一个小型gpt模型">构建一个小型GPT模型</h3>
<p>GPT属于因果语言模型（Causal Language Models, CLM）。它的任务是根据当前单词（token）预测下一个单词，是自然的无监督任务。比如，现在我们有一个莎士比亚的文本数据：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt" id="hl-0-1"><a class="lnlinks" href="#hl-0-1">1</a>
</span><span class="lnt" id="hl-0-2"><a class="lnlinks" href="#hl-0-2">2</a>
</span><span class="lnt" id="hl-0-3"><a class="lnlinks" href="#hl-0-3">3</a>
</span><span class="lnt" id="hl-0-4"><a class="lnlinks" href="#hl-0-4">4</a>
</span><span class="lnt" id="hl-0-5"><a class="lnlinks" href="#hl-0-5">5</a>
</span><span class="lnt" id="hl-0-6"><a class="lnlinks" href="#hl-0-6">6</a>
</span><span class="lnt" id="hl-0-7"><a class="lnlinks" href="#hl-0-7">7</a>
</span><span class="lnt" id="hl-0-8"><a class="lnlinks" href="#hl-0-8">8</a>
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-text" data-lang="text"><span class="line"><span class="cl">First Citizen:
</span></span><span class="line"><span class="cl">Before we proceed any further, hear me speak.
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">All:
</span></span><span class="line"><span class="cl">Speak, speak.
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">First Citizen:
</span></span><span class="line"><span class="cl">You are all resolved rather to die than to famish?
</span></span></code></pre></td></tr></table>
</div>
</div><p>它是由字符组成的，我们需要一个映射，将其转化为模型可接受的数字向量的输入格式。首先将句子进行分词，然后建立词表，再将每个单词映射到词表的索引。这样，我们可以构建GPT的dataloader：对于给定超参数batch_size=$B$，同时给定句子片段长度$T$，dataloader可以定义为从数据中随机采样$B$个连续的长度为$T$的句子片段，来得到一个batch的数据。如下图所示。</p>
<img src="https://raw.githubusercontent.com/yliuhz/blogs/master/content/posts/attn.png" width=70%/>
<p>接着定义模型架构。这里采用经典的Transformer架构 




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#3suxkdnn"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Ashish"><span itemprop="familyName">Vaswani</span></span>,&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Noam"><span itemprop="familyName">Shazeer</span></span>
                  <em>&amp; al.</em>,&#32;<span itemprop="datePublished">2017</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Vaswani</span>,&#32;
    <meta itemprop="givenName" content="Ashish" />
    A.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Shazeer</span>,&#32;
    <meta itemprop="givenName" content="Noam" />
    N.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Parmar</span>,&#32;
    <meta itemprop="givenName" content="Niki" />
    N.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Uszkoreit</span>,&#32;
    <meta itemprop="givenName" content="Jakob" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Jones</span>,&#32;
    <meta itemprop="givenName" content="Llion" />
    L.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Gomez</span>,&#32;
    <meta itemprop="givenName" content="Aidan N." />
    A.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Kaiser</span>,&#32;
    <meta itemprop="givenName" content="Lukasz" />
    L.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Polosukhin</span>,&#32;
    <meta itemprop="givenName" content="Illia" />
    I.</span>
  &#32;
    (<span itemprop="datePublished">2017</span>).
  &#32;<span itemprop="name">Attention Is All You Need</span>.
  <a href="https://doi.org/10.48550/arXiv.1706.03762"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.1706.03762</a></span>




</span></span>)</span>
。如下图所示。Transformer由左侧的编码器和右侧的解码器构成，GPT采用纯解码器结构，所以这里只考虑右侧。它由N个块组成，每个块内包含了(Masked) Multi-head Attention、Add &amp; Norm和FFN前馈网络。其中，Multi-head Attention是由多个attention块拼接起来的核心架构；Add &amp; Norm指residual connections和layernorm，用于模型的优化；FFN是常见的全连接网络。因此，首先关注核心的attention块。</p>
<img src="https://raw.githubusercontent.com/yliuhz/blogs/master/content/posts/iShot_2023-07-10_19.32.58.png" width=50%/>
<h3 id="self-attention-自注意力机制">Self-Attention 自注意力机制</h3>
<p>为了解决由前面的单词$\{\pmb{x}_1,\cdots,\pmb{x}_{l-1}\}$预测下一个单词$\pmb{x}_l$的任务，一个简单的做法是取已观测到的单词表征的平均，即</p>
<p>$$\pmb{x}_l=\frac{1}{l-1}\sum_{i=1}^{l-1}\pmb{x}_i$$</p>
<p>写成矩阵即为</p>
<p>$$
\begin{align}
\hat{\pmb{Y}} &amp;=\text{Softmax}(\text{Lower}(\text{ones}(T,T)))\pmb{X} \\
&amp;= \begin{bmatrix}
1       &amp; 0 &amp; 0 &amp; \dots &amp; 0 \\
1/2       &amp; 1/2 &amp; 0 &amp; \dots &amp; 0 \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots  \\
1/T       &amp; 1/T &amp; 1/T &amp; \dots &amp; 1/T
\end{bmatrix}_{T\times T}\times \pmb{X}_{T\times C} \label{eq1}\tag{1}
\end{align}
$$</p>
<p>但这不是最优的做法，因为可能只有某几个位置的单词对待预测单词是重要的，每个单词不应授予相同的权重。因此可以考虑加权平均。注意力机制就给了一种计算权重的方法。</p>
<p>假设一个长度为$T$的句子的表征向量为$\pmb{X}\in\mathbb{R}^{T\times C}$。注意力机制定义了3个向量$Q,K,V$，分别表示查询向量Query，键向量Key和值向量Value。在自注意力的条件下$Q,K,V$分别由$\pmb{X}$的3个线性函数得来，即</p>
<p>$$
\begin{aligned}
Q &amp;=\text{Linear}(\pmb{X}) &amp;&amp;=\pmb{X}\pmb{W}_Q+\pmb{b}_Q &amp;&amp;\in\mathbb{R}^{T\times h_s}\\
K &amp;=\text{Linear}(\pmb{X}) &amp;&amp;=\pmb{X}\pmb{W}_K+\pmb{b}_K  &amp;&amp;\in\mathbb{R}^{T\times h_s}\\
V &amp;=\text{Linear}(\pmb{X}) &amp;&amp;=\pmb{X}\pmb{W}_V+\pmb{b}_V &amp;&amp;\in\mathbb{R}^{T\times h_s}
\end{aligned}
$$</p>
<p>其中$h_s$表示输出头的维度，或称为head的维度，$\pmb{W}\in\mathbb{R}^{C\times h_s},\pmb{b}\in\mathbb{R}^{h_s}$。</p>
<p>每个Linear函数生成了输入$\pmb{x}$的一个代理。其中，$Q$中的每一行表示对应单词要查询的信息，$K$中每一行表示对应单词所包含的信息。这样，将$Q$的第$i$行与$K$的第$j$列做内积运算，就可以得到单词$j$是否对齐了单词$i$所要查找的信息。如果是，那么内积值会偏大，即我们想要的单词$j$对于单词$i$的权重会偏大。</p>
<p>因此，由$Q$和$K$计算权重矩阵，即$\text{Softmax}(\text{Lower}[QK^T])$，其中$\text{Lower}$表示取下三角矩阵，$\text{Softmax}$函数将权重规范化到$[0,1]$之间。这里$\text{Lower}$是由于在GPT的任务中，当前单词只能根据前面的单词预测，因此后面的权重是没有意义的，所以强制通过$\text{Lower}$赋成$0$。<a href="https://colab.research.google.com/drive/1JMLa53HDuA-i7ZBmqV7ZnA3c_fvtXnx-?usp=sharing">Colab notebook</a>中一个样例attention权重矩阵是</p>
<p>$$
\begin{aligned}
\text{Softmax}(QK^T) =
\begin{bmatrix}
1       &amp; 0 &amp; 0 &amp; \dots &amp; 0 \\
0.1574       &amp; 0.8426 &amp; 0 &amp; \dots &amp; 0 \\
0.2088  &amp; 0.1646    &amp; 0.6266 &amp; \dots &amp; 0 \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots  \\
0.0210       &amp; 0.0843 &amp; 0.0555 &amp; \dots &amp; 0.2391
\end{bmatrix}
\end{aligned}
$$</p>
<p>可以看到每个前置单词对于当前单词的权重不再相同，且每一行权重求和为$1$。</p>
<p>在得到权重矩阵后，将权重矩阵与值向量相乘，得到输出的词表征矩阵，即</p>
<p>$$\hat{\pmb{Y}} =\text{Softmax}(QK^T)V\in\mathbb{R}^{T\times h_s}$$</p>
<p>可以看到与上面 ($\ref{eq1}$) 式不同，自注意力机制中不是直接将权重矩阵与$\pmb{X}$相乘，而同样是用一个线性映射$V$将$\pmb{X}$包起来。<a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&amp;t=4185s">视频</a>中的讲解是$\pmb{X}$相当于句子的私有特征，而$V$是$\pmb{X}$与其他位置单词交流（传播）时所使用的特征。</p>
<!-- 这种在传播前再做一次映射的机制在图学习中也有体现，
比如在对比学习中，比较正负样本的表征时是在MLP映射后的新的映射空间做，而不是直接在GNN的输出空间做。 -->
<h3 id="关于self-attention的一些notes">关于Self Attention的一些Notes</h3>
<p>Andrej Karpathy在一个<a href="https://colab.research.google.com/drive/1JMLa53HDuA-i7ZBmqV7ZnA3c_fvtXnx-?usp=sharing">colab notebook</a>中写了关于attention的一些notes。</p>
<ul>
<li>Attention机制是一种信息传递机制。它可以被看做节点从它的邻居节点通过加权平均聚合信息，而每个权重值依赖于具体的邻居节点。</li>
<li>Attenion没有编码位置信息。所有聚合信息的单词对当前单词都是相同的，因此我们需要位置编码。</li>
<li>Attention只在batch内的单词间进行，不同batch间的单词永远是相互独立的。</li>
<li>这里我们只考虑了纯解码器的架构。如果考虑编码器中的attention块，那么只需要把上述表达式中的$\text{Lower}$函数去掉，让单词自由地聚合信息即可。纯解码器架构采用这种半三角的权重（masking），并经常用于NLP中的自回归任务。</li>
<li>Self Attention指的是$K,Q,V$由相同的输入向量$\pmb{X}$计算；反过来，Cross Attention则表示$Q$从原来的$\pmb{X}$计算，而$K,V$从其他来源计算，比如编码器的输出。而编码器-解码器的架构通常用于机器翻译任务中。编码器-解码器结构需要根据编码器的输入（如其他语言）进行输出（conditioned）。而解码器只根据前面的单词生成下面的单词（unconditioned）。</li>
<li>Scaled Attention的含义是对权重矩阵做额外放缩：即乘以$1/\text{sqrt(head_size)}$。它可以保持权重矩阵的方差，防止在经过$\text{Softmax}$函数后退化为独热向量。这在权重<strong>初始化</strong>时尤其重要：如果有邻居的权重过大，那么节点只会从该邻居聚合信息，这不是我们想要的。</li>
<li>Multi-head Attention（MHA）：并行地执行多个attention模块，将每个head的结果拼接作为最终输出。MHA可以提高Transformer模型的运行效率，并将学习到的不同层面的拼接在一起，有利于提高表征质量。</li>
<li>如<a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&amp;t=4185s">视频</a>中所述，self-attention是一种信息传递机制。每个节点在聚合了邻居节点的信息后，需要在预测logits之前进一步映射信息到另一个空间（原文：每个节点在互相看到彼此后，还没有来得及思考它们发现了什么），这是需要在self-attention后面连接FFN的原因。</li>
</ul>
<h3 id="深层transformer">深层Transformer</h3>
<ul>
<li>Residual Connections：$\hat{\pmb{Y}}=\text{Proj}(\pmb{X})+\text{Proj}(\text{Softmax}(QK^T)V)\in\mathbb{R}^{T\times C&rsquo;}$，其中$\text{Proj}$是线性映射，用于转换维度以确保能够相加。<a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&amp;t=4185s">视频</a>中引用了<a href="https://towardsdatascience.com/residual-blocks-building-blocks-of-resnet-fd90ca15d6ec">博客</a>。</li>
<li>LayerNorm：确保数据的每行具有$0$均值和$1$方差；与之正交的BatchNorm确保数据的每列具有$0$均值和$1$方差。</li>
</ul>
<h3 id="nano-gpt模型概览">Nano-GPT模型概览</h3>
<p>我们已经了解了构建GPT所需的所有模块。接下来小结一下GPT的预训练流程。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt" id="hl-1-1"><a class="lnlinks" href="#hl-1-1"> 1</a>
</span><span class="lnt" id="hl-1-2"><a class="lnlinks" href="#hl-1-2"> 2</a>
</span><span class="lnt" id="hl-1-3"><a class="lnlinks" href="#hl-1-3"> 3</a>
</span><span class="lnt" id="hl-1-4"><a class="lnlinks" href="#hl-1-4"> 4</a>
</span><span class="lnt" id="hl-1-5"><a class="lnlinks" href="#hl-1-5"> 5</a>
</span><span class="lnt" id="hl-1-6"><a class="lnlinks" href="#hl-1-6"> 6</a>
</span><span class="lnt" id="hl-1-7"><a class="lnlinks" href="#hl-1-7"> 7</a>
</span><span class="lnt" id="hl-1-8"><a class="lnlinks" href="#hl-1-8"> 8</a>
</span><span class="lnt" id="hl-1-9"><a class="lnlinks" href="#hl-1-9"> 9</a>
</span><span class="lnt" id="hl-1-10"><a class="lnlinks" href="#hl-1-10">10</a>
</span><span class="lnt" id="hl-1-11"><a class="lnlinks" href="#hl-1-11">11</a>
</span><span class="lnt" id="hl-1-12"><a class="lnlinks" href="#hl-1-12">12</a>
</span><span class="lnt" id="hl-1-13"><a class="lnlinks" href="#hl-1-13">13</a>
</span><span class="lnt" id="hl-1-14"><a class="lnlinks" href="#hl-1-14">14</a>
</span><span class="lnt" id="hl-1-15"><a class="lnlinks" href="#hl-1-15">15</a>
</span><span class="lnt" id="hl-1-16"><a class="lnlinks" href="#hl-1-16">16</a>
</span><span class="lnt" id="hl-1-17"><a class="lnlinks" href="#hl-1-17">17</a>
</span><span class="lnt" id="hl-1-18"><a class="lnlinks" href="#hl-1-18">18</a>
</span><span class="lnt" id="hl-1-19"><a class="lnlinks" href="#hl-1-19">19</a>
</span><span class="lnt" id="hl-1-20"><a class="lnlinks" href="#hl-1-20">20</a>
</span><span class="lnt" id="hl-1-21"><a class="lnlinks" href="#hl-1-21">21</a>
</span><span class="lnt" id="hl-1-22"><a class="lnlinks" href="#hl-1-22">22</a>
</span><span class="lnt" id="hl-1-23"><a class="lnlinks" href="#hl-1-23">23</a>
</span><span class="lnt" id="hl-1-24"><a class="lnlinks" href="#hl-1-24">24</a>
</span><span class="lnt" id="hl-1-25"><a class="lnlinks" href="#hl-1-25">25</a>
</span><span class="lnt" id="hl-1-26"><a class="lnlinks" href="#hl-1-26">26</a>
</span><span class="lnt" id="hl-1-27"><a class="lnlinks" href="#hl-1-27">27</a>
</span><span class="lnt" id="hl-1-28"><a class="lnlinks" href="#hl-1-28">28</a>
</span><span class="lnt" id="hl-1-29"><a class="lnlinks" href="#hl-1-29">29</a>
</span><span class="lnt" id="hl-1-30"><a class="lnlinks" href="#hl-1-30">30</a>
</span><span class="lnt" id="hl-1-31"><a class="lnlinks" href="#hl-1-31">31</a>
</span><span class="lnt" id="hl-1-32"><a class="lnlinks" href="#hl-1-32">32</a>
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">GPTLanguageModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># each token directly reads off the logits for the next token from a lookup table</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">token_embedding_table</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">n_embd</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">position_embedding_table</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">block_size</span><span class="p">,</span> <span class="n">n_embd</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">blocks</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">Block</span><span class="p">(</span><span class="n">n_embd</span><span class="p">,</span> <span class="n">n_head</span><span class="o">=</span><span class="n">n_head</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layer</span><span class="p">)])</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">ln_f</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">n_embd</span><span class="p">)</span> <span class="c1"># final layer norm</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">lm_head</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_embd</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">,</span> <span class="n">targets</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">B</span><span class="p">,</span> <span class="n">T</span> <span class="o">=</span> <span class="n">idx</span><span class="o">.</span><span class="n">shape</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># idx and targets are both (B,T) tensor of integers</span>
</span></span><span class="line"><span class="cl">        <span class="n">tok_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_embedding_table</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span> <span class="c1"># (B,T,C)</span>
</span></span><span class="line"><span class="cl">        <span class="n">pos_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">position_embedding_table</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">))</span> <span class="c1"># (T,C)</span>
</span></span><span class="line"><span class="cl">        <span class="n">x</span> <span class="o">=</span> <span class="n">tok_emb</span> <span class="o">+</span> <span class="n">pos_emb</span> <span class="c1"># (B,T,C)</span>
</span></span><span class="line"><span class="cl">        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">blocks</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># (B,T,C)</span>
</span></span><span class="line"><span class="cl">        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ln_f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># (B,T,C)</span>
</span></span><span class="line"><span class="cl">        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_head</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># (B,T,vocab_size)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">targets</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">B</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">C</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span>
</span></span><span class="line"><span class="cl">            <span class="n">logits</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">B</span><span class="o">*</span><span class="n">T</span><span class="p">,</span> <span class="n">C</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">targets</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">B</span><span class="o">*</span><span class="n">T</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">logits</span><span class="p">,</span> <span class="n">loss</span>
</span></span><span class="line"><span class="cl">    <span class="o">...</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>首先采样一个batch的训练数据，规格为$B\times T$，每个位置的元素表示单词在词表中的下标，训练数据的标签为输入数据在句子中向后错一位的句子片段；接着讲数据输入到模型中。Nano-GPT采用查表获取单词的表征，规格为$B\times T\times C$，并为句子片段中的$T$个位置通过查表得到位置编码，规格为$T\times C$，将单词表征和位置编码求和得到输入MHA的表征。接着，表征经过MHA、LayerNorm和输出头得到预测的标签logits。NanoGPT采用交叉熵损失训练。</p>
<h3 id="利用nanogpt生成文本">利用NanoGPT生成文本</h3>
<p>GPT是纯解码器模型，这意味着输入一句话，GPT能够帮我们续写成一段话。</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Unsupervised Deep Graph Structure Learning</title>
      <link>https://yliuhz.github.io/blogs/posts/gslearning/</link>
      <pubDate>Tue, 27 Jun 2023 09:59:56 +0800</pubDate>
      
      <guid>https://yliuhz.github.io/blogs/posts/gslearning/</guid>
      <description>现实中图的结构可能是不完整或有噪声的。为了在图结构不可靠的情况下较好地完成下游任务，研究者提出了如下的图结构学习算法。
Towards Unsupervised Deep Graph Structure Learning 论文链接： ( Citation: Liu,&amp;#32;Zheng &amp;amp; al.,&amp;#32;2022 Liu,&amp;#32; Y.,&amp;#32; Zheng,&amp;#32; Y.,&amp;#32; Zhang,&amp;#32; D.,&amp;#32; Chen,&amp;#32; H.,&amp;#32; Peng,&amp;#32; H.&amp;#32;&amp;amp;&amp;#32;Pan,&amp;#32; S. &amp;#32; (2022). &amp;#32;Towards Unsupervised Deep Graph Structure Learning. https://doi.org/10.48550/arXiv.2201.06367 ) 相关工作 - 深度图结构学习 一些传统机器学习算法，如图信号处理，谱聚类，图论等可以解决图结构学习问题。但这类方法往往不能处理图上的高维属性。
最近的深度图结构学习方法用于提升GNN在下游任务上的性能。它们遵循相似的管线：先使用一组可学习的参数建模图的邻接矩阵，再和GNN的参数一起针对下游任务进行优化。基于图结构离散的特性，有多种建模图结构的方法。
概率模型：伯努利概率模型、随机块模型 度量学习：余弦相似度、点积 直接使用$n\times n$的参数矩阵建模邻接矩阵 问题定义 给定输入图$G=(V,E,X)=(A,X)$，$|V|=n,|E|=m,X\in\mathbb{R}^{n\times d}$
结构推理问题：输入信息只有顶点特征矩阵$X$ 结构修改问题：输入信息包含了$A,X$，但$A$可能带有噪声 解决方案 - SUBLIME SUBLIME ( Citation: Liu,&amp;#32;Zheng &amp;amp; al.,&amp;#32;2022 Liu,&amp;#32; Y.,&amp;#32; Zheng,&amp;#32; Y.,&amp;#32; Zhang,&amp;#32; D.,&amp;#32; Chen,&amp;#32; H.,&amp;#32; Peng,&amp;#32; H.&amp;#32;&amp;amp;&amp;#32;Pan,&amp;#32; S. &amp;#32; (2022). &amp;#32;Towards Unsupervised Deep Graph Structure Learning.</description>
      <content:encoded><![CDATA[<p>现实中图的结构可能是不完整或有噪声的。为了在图结构不可靠的情况下较好地完成下游任务，研究者提出了如下的图结构学习算法。</p>
<h2 id="towards-unsupervised-deep-graph-structure-learning">Towards Unsupervised Deep Graph Structure Learning</h2>
<p>论文链接：




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#14nyansau"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Yixin"><span itemprop="familyName">Liu</span></span>,&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Yu"><span itemprop="familyName">Zheng</span></span>
                  <em>&amp; al.</em>,&#32;<span itemprop="datePublished">2022</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Liu</span>,&#32;
    <meta itemprop="givenName" content="Yixin" />
    Y.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Zheng</span>,&#32;
    <meta itemprop="givenName" content="Yu" />
    Y.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Zhang</span>,&#32;
    <meta itemprop="givenName" content="Daokun" />
    D.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Chen</span>,&#32;
    <meta itemprop="givenName" content="Hongxu" />
    H.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Peng</span>,&#32;
    <meta itemprop="givenName" content="Hao" />
    H.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Pan</span>,&#32;
    <meta itemprop="givenName" content="Shirui" />
    S.</span>
  &#32;
    (<span itemprop="datePublished">2022</span>).
  &#32;<span itemprop="name">Towards Unsupervised Deep Graph Structure Learning</span>.
  <a href="https://doi.org/10.48550/arXiv.2201.06367"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.2201.06367</a></span>




</span></span>)</span>
</p>
<h3 id="相关工作---深度图结构学习">相关工作 - 深度图结构学习</h3>
<p>一些传统机器学习算法，如图信号处理，谱聚类，图论等可以解决图结构学习问题。但这类方法往往不能处理图上的高维属性。</p>
<p>最近的深度图结构学习方法用于提升GNN在下游任务上的性能。它们遵循相似的管线：先使用一组可学习的参数建模图的邻接矩阵，再和GNN的参数一起针对下游任务进行优化。基于图结构离散的特性，有多种建模图结构的方法。</p>
<ul>
<li>概率模型：伯努利概率模型、随机块模型</li>
<li>度量学习：余弦相似度、点积</li>
<li>直接使用$n\times n$的参数矩阵建模邻接矩阵</li>
</ul>
<h3 id="问题定义">问题定义</h3>
<p>给定输入图$G=(V,E,X)=(A,X)$，$|V|=n,|E|=m,X\in\mathbb{R}^{n\times d}$</p>
<ul>
<li><strong>结构推理问题</strong>：输入信息只有顶点特征矩阵$X$</li>
<li><strong>结构修改问题</strong>：输入信息包含了$A,X$，但$A$可能带有噪声</li>
</ul>
<h3 id="解决方案---sublime">解决方案 - SUBLIME</h3>
<p>SUBLIME 




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#14nyansau"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Yixin"><span itemprop="familyName">Liu</span></span>,&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Yu"><span itemprop="familyName">Zheng</span></span>
                  <em>&amp; al.</em>,&#32;<span itemprop="datePublished">2022</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Liu</span>,&#32;
    <meta itemprop="givenName" content="Yixin" />
    Y.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Zheng</span>,&#32;
    <meta itemprop="givenName" content="Yu" />
    Y.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Zhang</span>,&#32;
    <meta itemprop="givenName" content="Daokun" />
    D.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Chen</span>,&#32;
    <meta itemprop="givenName" content="Hongxu" />
    H.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Peng</span>,&#32;
    <meta itemprop="givenName" content="Hao" />
    H.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Pan</span>,&#32;
    <meta itemprop="givenName" content="Shirui" />
    S.</span>
  &#32;
    (<span itemprop="datePublished">2022</span>).
  &#32;<span itemprop="name">Towards Unsupervised Deep Graph Structure Learning</span>.
  <a href="https://doi.org/10.48550/arXiv.2201.06367"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.2201.06367</a></span>




</span></span>)</span>
 将学习到的图结构视作一种<strong>数据增强</strong>，与原图进行多视角的对比学习。</p>
<img src="https://raw.githubusercontent.com/yliuhz/blogs/master/content/posts/iShot_2023-06-27_10.22.17.png" />
<ul>
<li><strong>锚点视角（教师）</strong>：对于输入带有邻接矩阵$A$的结构修改任务，直接使用输入的$A$作为锚点；对于输入不带邻接矩阵的结构推理任务，使用单位矩阵$I$作为锚点。节点特征使用输入特征$X$。</li>
<li><strong>结构学习器视角（学生）</strong>：使用结构学习器的输出作为该视角。节点特征使用输入特征$X$。</li>
</ul>
<p>SUBLIME定义了四种图结构学习器，使用时需要当作超参数调节：</p>
<ul>
<li>
<p><strong>全图参数化学习器FGP</strong>：顾名思义，直接使用一个$n\times n$的参数矩阵作为学习的邻接矩阵，即$S=\sigma(\Omega)$，$\Omega\in\mathbb{R}^{n\times n}$；</p>
<ul>
<li><strong>初始化</strong>：使用节点特征的$k$最近邻初始化$\Omega$。<a href="https://github.com/GRAND-Lab/SUBLIME/blob/93398db994f21bd2b03f15db414e1e03244144e9/graph_learners.py#L19">github link</a></li>
</ul>
</li>
<li>
<p><strong>度量学习学习器</strong>：先通过输入得到节点的表征$E\in\mathbb{R}^{n\times d}$，再由表征构建学习的邻接矩阵：</p>
</li>
</ul>
<p>$$S=\phi(h_w(X,A))=\phi(E)$$</p>
<p>其中$\phi$是非参数函数（即不用训练的函数），如余弦相似度、闵可夫斯基距离（Minkowski distance）等；$h_w$是表征网络。SUBLIME提供了3种得到$E$的表征方法：注意力学习器、MLP学习器和GNN学习器：</p>
<ul>
<li>
<p><strong>注意力学习器</strong>：$E^{(l)}=h_w^{(l)}(E^{(l-1)})=\sigma([e_1^{(l-1)}\odot w^{(l)},\cdots,e_n^{(l-1)}\odot w^{(l)}])^T$，其中$E^{(l)}\in\mathbb{R}^{n\times d}$表示第$l$层表征网络的输出；$e_i^{(l-1)}\in\mathbb{R}^d$表示$E^{(l-1)}$的第$i$行，$w^{(l)}\in\mathbb{R}^d$为权重向量。初始时$E^{(0)}=X$。可以看到该表征学习器没有对特征进行降维，每一层的输出$E$的维度都是$\mathbb{R}^{n\times d}$。</p>
<ul>
<li><strong>初始化</strong>：$w^{(l)}$初始为全$1$向量，即$w^{(l)}=\{1,1,\cdots,1\}\in\mathbb{R}^d$。<a href="https://github.com/GRAND-Lab/SUBLIME/blob/93398db994f21bd2b03f15db414e1e03244144e9/layers.py#L40">github link</a></li>
</ul>
</li>
<li>
<p><strong>MLP学习器</strong>：$E^{(l)}=h_w^{(l)}(E^{(l-1)})=\sigma(E^{(l-1)}\Omega^{(l)})$，其中$\Omega^{(l)}\in\mathbb{R}^{d\times d}$是参数矩阵。</p>
<ul>
<li><strong>初始化</strong>：$\Omega$初始时为单位矩阵。<a href="https://github.com/GRAND-Lab/SUBLIME/blob/93398db994f21bd2b03f15db414e1e03244144e9/graph_learners.py#L109">github link</a></li>
</ul>
</li>
<li>
<p><strong>GNN学习器</strong>：$E^{(l)}=h_w^{(l)}(E^{(l-1)})=\sigma(\tilde{D}^{-1/2}\tilde{A}\tilde{D}^{-1/2}E^{(l-1)}\Omega^{(l)})$，其中$\Omega^{(l)}\in\mathbb{R}^{d\times d}$是参数矩阵。</p>
<ul>
<li><strong>初始化</strong>：$\Omega$初始时为单位矩阵。<a href="https://github.com/GRAND-Lab/SUBLIME/blob/93398db994f21bd2b03f15db414e1e03244144e9/graph_learners.py#L167">github link</a></li>
</ul>
</li>
</ul>
<p>图学习器得到的$S$是全连接的，且不一定对称，所以需要进行后处理：即<strong>稀疏化</strong>、<strong>对称化</strong>和<strong>正则化</strong>。</p>
<ul>
<li><strong>稀疏化</strong>采用$k$最近邻方法，对每个顶点只保留最近的$k$的邻居。</li>
<li><strong>对称化</strong>：$S^{sym}=(\sigma(S)+\sigma(S)^T)/2$，其中$\sigma$是ReLU或ELU函数，保证$S&rsquo;$内的元素都是非负数。</li>
<li><strong>正则化</strong>：为保证边权都位于$[0,1]$范围，使用常用的图正则方法：$S&rsquo;=\tilde{D}^{-1/2}\tilde{S}^{sym}\tilde{D}^{-1/2}$。</li>
</ul>
<p>得到两个视角的图（锚点视角和学习器视角）后，SUBLIME对每个视角做进一步的数据增强，包括特征扰动和边的扰动。接着，使用GNN编码器（这里使用GCN）将两个视角的图映射到欧氏空间，再使用MLP进一步映射，在MLP的输出上使用节点级别的对比学习损失函数，即最大化同一节点在两个视角图之间的互信息：</p>
<p>$$\begin{aligned}\mathcal{L} &amp;=\frac{1}{2n}\left[l(z_{l,i},z_{a,i})+l(z_{a,i},z_{l,i})\right]\\
l(z_{l,i},z_{a,i}) &amp;= \log\frac{\exp(\cos(z_{l,i},z_{a,i})/t)}{\sum_{k=1}^n\exp(\cos(z_{l,i},z_{a,k})/t)}\end{aligned}$$</p>
<p>其中$t$是温度超参数。</p>
<p>除了使用梯度下降更新参数外，SUBLIME在每个epoch使用bootstrapping更新锚点视角的图结构，以减少噪声和过拟合的影响：</p>
<p>$$A_a\gets \tau A_a+(1-\tau)S$$</p>
<p>其中$A_a$是锚点视角图的邻接矩阵，$S$是图结构学习器输出的图结构。$\tau\in\{0.999,0.9999,0.99999\}$。<a href="https://github.com/GRAND-Lab/SUBLIME/blob/93398db994f21bd2b03f15db414e1e03244144e9/main.py#L213-L221">github link</a></p>
<h2 id="slaps-self-supervision-improves-structure-learning-for-graph-neural-networks">SLAPS: Self-Supervision Improves Structure Learning for Graph Neural Networks</h2>
<p>论文链接：




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#19efwtvyy"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Bahare"><span itemprop="familyName">Fatemi</span></span>,&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Layla El"><span itemprop="familyName">Asri</span></span>
                  <em>&amp; al.</em>,&#32;<span itemprop="datePublished">2021</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Fatemi</span>,&#32;
    <meta itemprop="givenName" content="Bahare" />
    B.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Asri</span>,&#32;
    <meta itemprop="givenName" content="Layla El" />
    L.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Kazemi</span>,&#32;
    <meta itemprop="givenName" content="Seyed Mehran" />
    S.</span>
  &#32;
    (<span itemprop="datePublished">2021</span>).
  &#32;<span itemprop="name">SLAPS: Self-Supervision Improves Structure Learning for Graph Neural Networks</span>.
  <a href="https://doi.org/10.48550/arXiv.2102.05034"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.2102.05034</a></span>




</span></span>)</span>
</p>
<!-- ### 相关工作

作者罗列了图结构学习的可能方法：

- **相似度矩阵**：根据节点之间的相似度，使用$k$最近邻等方法将节点与最相近的$k$个邻居节点相连。
- **全连接图**：
- **图学习**：
- **领域知识**： -->
<h3 id="问题定义-1">问题定义</h3>
<p>本文未考虑输入的图结构，只考虑利用输入的节点特征学习图结构。</p>
<h3 id="解决方案---slaps">解决方案 - SLAPS</h3>
<p>SLAPS包含4个模块：生成器、邻接关系处理器、分类器和自监督。</p>
<h4 id="生成器">生成器</h4>
<p>生成器是由节点特征到邻接矩阵的映射：$\mathbb{R}^{n\times d}\to\mathbb{R}^{n\times n}$。SLAPS给出了两种生成器：</p>
<ul>
<li>全参数FP：使用$n^2$个参数直接表示邻接矩阵</li>
<li>MLP-$k$NN：$\tilde{A}=kNN(MLP(X))$，其中MLP：$\mathbb{R}^{n\times d}\to\mathbb{R}^{n\times d&rsquo;}$；$k$NN：$\mathbb{R}^{n\times d&rsquo;}\to\mathbb{R}^{n\times n}$</li>
</ul>
<p>SLAPS初始化两种生成器使其生成$A^{kNN}$，即由输入节点特征$X$计算的$k$最近邻邻接矩阵。对于FP，直接将参数初始化为$A^{kNN}$即可；对于MLP-$k$NN，将MLP初始化为单位矩阵即可。MLP-$k$NN的两种变体：（1）MLP：$d&rsquo;\equiv d$；（2）MLP-D：参数矩阵是对角矩阵，其他元素为0。</p>
<h4 id="邻接关系处理器">邻接关系处理器</h4>
<p>设生成器输出的邻接矩阵为$\tilde{A}$，那么</p>
<p>$$A=\frac{1}{2}D^{-1/2}(P(\tilde{A})+P(\tilde{A})^T)D^{-1/2}$$</p>
<p>其中$P$是一个函数，取值范围为非负数。$A$保证了对称性和元素的非负性。</p>
<h4 id="分类器">分类器</h4>
<p>分类器：$\mathbb{R}^{n\times d}\times \mathbb{R}^{n\times n}\to \mathbb{R}^{n\times |C|}$取节点特征$X$和生成的邻接矩阵$A$作为输入，输出节点的类别标签。分类器的训练损失为交叉熵$\mathcal{L}_C$。</p>
<h4 id="自监督">自监督</h4>
<p>作者发现单独的交叉熵分类损失会导致生成的邻接矩阵中包含一些随机的边，因为这些边是否存在不会对半监督的交叉熵损失造成影响。同时在基准数据集上，这些随机边的比例较高。
于是，作者额外加入一个去躁自编码器DAE预测节点特征。</p>
<p>最终的损失函数定义为$\mathcal{L}=\mathcal{L}_C+\mathcal{L}_{DAE}$。SUBLIME在对比SLAPS时，无监督的条件下只使用$\mathcal{L}_{DAE}$。</p>
<h2 id="diffusion-improves-graph-learning">Diffusion Improves Graph Learning</h2>
<p>论文链接：




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#pxpd62wl"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Johannes"><span itemprop="familyName">Gasteiger</span></span>,&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Stefan"><span itemprop="familyName">Weißenberger</span></span>
                  <em>&amp; al.</em>,&#32;<span itemprop="datePublished">2022</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Gasteiger</span>,&#32;
    <meta itemprop="givenName" content="Johannes" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Weißenberger</span>,&#32;
    <meta itemprop="givenName" content="Stefan" />
    S.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Günnemann</span>,&#32;
    <meta itemprop="givenName" content="Stephan" />
    S.</span>
  &#32;
    (<span itemprop="datePublished">2022</span>).
  &#32;<span itemprop="name">Diffusion Improves Graph Learning</span>.
  <a href="https://doi.org/10.48550/arXiv.1911.05485"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.1911.05485</a></span>




</span></span>)</span>
，实际发表于NIPS2019，作者在2022年又在arXiv上传了一个新版本。</p>
<p>Diffusion是一种图结构增强的方法。本文主张使用增强后的图结构输入现有模型，而 




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#5h4nt6ww"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Kaveh"><span itemprop="familyName">Hassani</span></span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Amir Hosein"><span itemprop="familyName">Khasahmadi</span></span>,&#32;<span itemprop="datePublished">2020</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Hassani</span>,&#32;
    <meta itemprop="givenName" content="Kaveh" />
    K.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Khasahmadi</span>,&#32;
    <meta itemprop="givenName" content="Amir Hosein" />
    A.</span>
  &#32;
    (<span itemprop="datePublished">2020</span>).
  &#32;<span itemprop="name">Contrastive Multi-View Representation Learning on Graphs</span>.
  <a href="https://doi.org/10.48550/arXiv.2006.05582"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.2006.05582</a></span>




</span></span>)</span>
 将原图和diffusion后的图作为两个视角进行多视角学习。</p>
<p><strong>广义图扩散</strong>：$S=\sum_{k=0}^{\infty}\theta_k T^k$，其中$\theta_k$和$T^k$的选择需要确保该级数是收敛的。
本文使用了更严格的条件，即要求$\sum_{k=0}^{\infty}\theta_k=1,\theta_k\in[0,1]$，且$T$的特征值$\lambda_i\in[0,1]$。这两个要求是$S$收敛的充分条件。
$T$称为转移矩阵。</p>
<ul>
<li><strong>转移矩阵</strong>：转移矩阵可以选择随机游走转移矩阵$T_{rw}=AD^{-1}$和对称转移矩阵$T_{sym}=D^{-1/2}AD^{-1/2}$，其中$D_{ii}=\sum_{j=1}^NA_{ij}$表示度矩阵。$T_{rw}$是列随机矩阵（column-stochastic），即每一列的求和等于$1$。进一步地，可以定义</li>
</ul>
<p>$$\tilde{T}_{sym}=(w_{loop}I_N+D)^{-1/2}(w_{loop}I_N+A)(w_{loop}I_N+D)^{-1/2}$$</p>
<p>其中$w_{loop}\in\mathbb{R}^+$，表示随机游走以$p_{stay,i}=w_{loop}/D_i$停留在$i$节点。</p>
<ul>
<li>
<p><strong>扩散的例子</strong>：两个常用的图扩散是Personalized PageRank（PPR）和热核（the heat kernel）。</p>
<ul>
<li>PPR: $T=T_{rw}$，$\theta_k^{PPR}=\alpha(1-\alpha)^k$，$\alpha\in(0,1)$</li>
<li>热核：$T=T_{rw}$，$\theta_k^{HK}=e^{-t}\frac{t^k}{k!}$</li>
<li>近似图卷积：$T=\tilde{T}^{sym}$，$w_{loop}=1$，$\theta_1=1,\theta_k=0,\forall k\neq 1$</li>
</ul>
</li>
<li>
<p><strong>稀疏化</strong>：$S$通常是稠密的。可以用top-$k$或$\epsilon$-阈值法剔除$S$中的部分元素。</p>
</li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>Generalization of GNNs and MLPs</title>
      <link>https://yliuhz.github.io/blogs/posts/gnn-ood/</link>
      <pubDate>Mon, 26 Jun 2023 20:08:51 +0800</pubDate>
      
      <guid>https://yliuhz.github.io/blogs/posts/gnn-ood/</guid>
      <description>本文是 ( Citation: Xu,&amp;#32;Zhang &amp;amp; al.,&amp;#32;2021 Xu,&amp;#32; K.,&amp;#32; Zhang,&amp;#32; M.,&amp;#32; Li,&amp;#32; J.,&amp;#32; Du,&amp;#32; S.,&amp;#32; Kawarabayashi,&amp;#32; K.&amp;#32;&amp;amp;&amp;#32;Jegelka,&amp;#32; S. &amp;#32; (2021). &amp;#32;How Neural Networks Extrapolate: From Feedforward to Graph Neural Networks. https://doi.org/10.48550/arXiv.2009.11848 ) 的论文解读。OpenReview显示这篇论文是ICLR2021的Oral论文（前5%）。
引言 人类具有泛化性，例如学会算术后可以应用到任意大的数字。对于神经网络而言，前馈网络（也叫多层感知机，MLPs）在学习简单的多项式函数时就不能很好地泛化了。然而，基于MLP的图神经网络（GNNs）却在近期的一些任务上表现出较好的泛化性，包括预测物理系统的演进规律，学习图论算法，解决数学公式等。 粗略地分析可能会觉得神经网络可以在训练分布以外的数据上有任意不确定的表现，但是现实中的神经网络大多是用梯度下降训练的，这就导致其泛化性能有规律可以分析。作者使用&amp;quot;神经切线核&amp;quot;（neural tangent kernel，NTK）工具进行分析。
本文的第一个结论是使用梯度下降训练的MLPs会收敛到任意方向线性的函数，因此MLPs在大多数非线性任务上无法泛化。
接着本文将分析延伸到基于MLP的GNNs，得到第二个结论：使用线性对齐简化目标函数使得基于MLP的GNNs在非线性任务上能够泛化，即将非线性部分提前集成在模型的结构（如GNN的聚合和读出函数）或在输入的表征向量中（使用无监督方法将输入特征转化为表征向量）。
前置知识 设$\mathcal{X}$表示数据（向量或图）的域。任务是学习一个函数$g:\mathcal{X}\to \mathbb{R}$，其中训练数据$\{(\pmb{x}_i,y_i)\}\in\mathcal{D}$，$y_i=g(\pmb{x_i})$，$\mathcal{D}$表示训练数据的分布。在训练数据和测试数据同分布的情况下，$\mathcal{D}=\mathcal{X}$；而在评估泛化能力时，$\mathcal{D} $是$\mathcal{X}$的子集。一个模型的泛化能力可以用泛化误差评估：设$f$为模型在训练数据上得到的函数，$l$为任意损失函数，则泛化误差定义为$\mathbb{E}_{\pmb{x}\sim \mathcal{X} \setminus \mathcal{D}}[l(f(\pmb{x}), g(\pmb{x}))]$
图神经网络GNNs是在MLPs基础上定义的网络。具体来说，初始顶点表征为$\pmb{h}_u^{(0)}=\pmb{x}_u$。在第$k={1..K}$层，顶点表征更新公式为
$$\begin{aligned}\pmb{h}_u^{(k)}&amp;amp;=\sum_{v\in\mathcal{N}(u)}\text{MLP}^{(k)}(\pmb{h}_u^{(k-1)},\pmb{h}_v^{(k-1)},\pmb{w}_{(v,u)}) \\ \pmb{h}_G&amp;amp;=\text{MLP}^{(K+1)}(\sum_{u\in G}\pmb{h}_u^{(K)})\end{aligned}$$
其中$\pmb{h}_u^{(k)}$表示第$k$层GNN输出的顶点$u$的表征，$\pmb{h}_G$表示整张图的表征。$\pmb{h}_u^{(k)}$的计算过程称为聚合，$\pmb{h}_G$的计算过程称为读出。以往研究大多使用$\text{sum}$聚合与$\text{sum}$读出，而本文指出替换为另外的函数能够提升泛化性能。
前馈网络MLPs如何泛化 ReLU MLPs的线性泛化 作者用下图呈现MLPs的泛化方式。灰色表示MLPs要学习的真实函数，蓝色和黑色分别表示模型在训练集和测试集上的预测。可以看到模型可以拟合训练集上的非线性函数，但脱离训练集后迅速变为线性函数。用数字来说，脱离训练集后MLPs预测的决定系数大于$0.99$。
定理1（线性泛化）：假设在NTK机制下使用均方误差训练了一个两层MLP：$f:\mathbb{R}^d\to\mathbb{R}$。对于任意方向$\pmb{v}\in\mathbb{R}^d$，令$\pmb{x}_0=t\pmb{v}$，那么当$t\to\infty$时，$f(\pmb{x}_0+h\pmb{v})-f(\pmb{x}_0)\to\beta_vh$对任意的$h&amp;gt;0$成立，$\beta_v$是常数。进一步地，给定$\epsilon&amp;gt;0$，对于$t=O(\frac{1}{\epsilon})$，$|\frac{f(\pmb{x}_0+h\pmb{v})-f(\pmb{x}_0)}{h}-\beta_v|&amp;lt;\epsilon$。
定理1说明了在训练数据集以外，ReLU MLPs可以拟合几乎线性的函数。对于二次函数（$\pmb{x}^TA\pmb{x}$）、余弦函数($\sum_{i=1}^d\cos(2\pi\cdot\pmb{x}^{(i)})$)、根次函数（$\sum_{i=1}^d\sqrt{\pmb{x}^{(i)}}$）等，ReLU MLPs不能泛化。 在合适的超参数下，MLPs可以正确地泛化L1范数，与定理1一致。如下图所示。
ReLU MLPs什么时候一定（provably）可以泛化 尽管上图显示MLPs对于线性函数可以较好地泛化，但这需要一定的条件，即训练数据集的分布必须足够“多样”。下面的引理1指出只需要$2d$条认真挑选的数据就可以实现ReLU MLPs的线性泛化。
引理1：令$g(\pmb{x})=\pmb{\beta}^T\pmb{x}$表示待拟合的目标函数，$\pmb{\beta}\in\mathbb{R}^d$。假设数据集$\{\pmb{x}_i\}_{i=1}^n$包含正交基$\{\hat{\pmb{x}}_i\}_{i=1}^d$和$\{-\hat{\pmb{x}}_i\}_{i=1}^d$。若使用均方误差在$\{({\pmb{x}}_i,y_i)\}_{i=1}^n$上训练一个两层ReLU MLP，那么$f({\pmb{x}})={\pmb{\beta}}^T{\pmb{x}}$对任意的${\pmb{x}}\in\mathbb{R}^d$成立。
然而，仔细挑选出$2d$条符合条件的样本并不容易。下面的定理2基于更现实的场景，指出只要训练数据的分布包含所有的方向（例如一个包含原点的超球），那么在足够的训练数据量下MLP能够收敛到线性函数。
定理2（泛化的条件）：令$g(\pmb{x})=\pmb{\beta}^T\pmb{x}$表示待拟合的目标函数，$\pmb{\beta}\in\mathbb{R}^d$。假设$\{\pmb{x}_i\}_{i=1}^n$从域$\mathcal{D}$中采样，其中$\mathcal{D}$包含一个连通的子集$S$，满足对任意非零向量$\pmb{w}\in\mathbb{R}^d$，存在$k&amp;gt;0$使得$k\pmb{w}\in S$。若在NTK机制下，使用均方误差在$\{({\pmb{x}}_i,y_i)\}_{i=1}^n$上训练一个两层ReLU MLP，$f(\pmb{x})\xrightarrow{p}\pmb{\beta}^T\pmb{x}$在$n\to\infty$时成立，即$f$依概率收敛到$g$。</description>
      <content:encoded><![CDATA[<p>本文是 




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#18wo6er1h"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Keyulu"><span itemprop="familyName">Xu</span></span>,&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Mozhi"><span itemprop="familyName">Zhang</span></span>
                  <em>&amp; al.</em>,&#32;<span itemprop="datePublished">2021</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Xu</span>,&#32;
    <meta itemprop="givenName" content="Keyulu" />
    K.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Zhang</span>,&#32;
    <meta itemprop="givenName" content="Mozhi" />
    M.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Li</span>,&#32;
    <meta itemprop="givenName" content="Jingling" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Du</span>,&#32;
    <meta itemprop="givenName" content="Simon S." />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Kawarabayashi</span>,&#32;
    <meta itemprop="givenName" content="Ken-ichi" />
    K.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Jegelka</span>,&#32;
    <meta itemprop="givenName" content="Stefanie" />
    S.</span>
  &#32;
    (<span itemprop="datePublished">2021</span>).
  &#32;<span itemprop="name">How Neural Networks Extrapolate: From Feedforward to Graph Neural Networks</span>.
  <a href="https://doi.org/10.48550/arXiv.2009.11848"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.2009.11848</a></span>




</span></span>)</span>
 的论文解读。OpenReview显示这篇论文是ICLR2021的Oral论文（前5%）。</p>
<h2 id="引言">引言</h2>
<p>人类具有泛化性，例如学会算术后可以应用到任意大的数字。对于神经网络而言，前馈网络（也叫多层感知机，MLPs）在学习简单的多项式函数时就不能很好地泛化了。然而，基于MLP的图神经网络（GNNs）却在近期的一些任务上表现出较好的泛化性，包括预测物理系统的演进规律，学习图论算法，解决数学公式等。
粗略地分析可能会觉得神经网络可以在训练分布以外的数据上有任意不确定的表现，但是现实中的神经网络大多是用梯度下降训练的，这就导致其泛化性能有规律可以分析。作者使用&quot;神经切线核&quot;（neural tangent kernel，NTK）工具进行分析。</p>
<p>本文的第一个结论是使用梯度下降训练的MLPs会收敛到任意方向线性的函数，因此<strong>MLPs在大多数非线性任务上无法泛化</strong>。</p>
<p>接着本文将分析延伸到基于MLP的GNNs，得到第二个结论：<strong>使用线性对齐简化目标函数使得基于MLP的GNNs在非线性任务上能够泛化，即将非线性部分提前集成在模型的结构（如GNN的聚合和读出函数）或在输入的表征向量中（使用无监督方法将输入特征转化为表征向量）。</strong></p>
<h2 id="前置知识">前置知识</h2>
<p>设$\mathcal{X}$表示数据（向量或图）的域。任务是学习一个函数$g:\mathcal{X}\to \mathbb{R}$，其中训练数据$\{(\pmb{x}_i,y_i)\}\in\mathcal{D}$，$y_i=g(\pmb{x_i})$，$\mathcal{D}$表示训练数据的分布。在训练数据和测试数据同分布的情况下，$\mathcal{D}=\mathcal{X}$；而在评估泛化能力时，$\mathcal{D}
$是$\mathcal{X}$的子集。一个模型的泛化能力可以用<strong>泛化误差</strong>评估：设$f$为模型在训练数据上得到的函数，$l$为任意损失函数，则泛化误差定义为$\mathbb{E}_{\pmb{x}\sim \mathcal{X} \setminus \mathcal{D}}[l(f(\pmb{x}), g(\pmb{x}))]$</p>
<p>图神经网络GNNs是在MLPs基础上定义的网络。具体来说，初始顶点表征为$\pmb{h}_u^{(0)}=\pmb{x}_u$。在第$k={1..K}$层，顶点表征更新公式为</p>
<p>$$\begin{aligned}\pmb{h}_u^{(k)}&amp;=\sum_{v\in\mathcal{N}(u)}\text{MLP}^{(k)}(\pmb{h}_u^{(k-1)},\pmb{h}_v^{(k-1)},\pmb{w}_{(v,u)}) \\
\pmb{h}_G&amp;=\text{MLP}^{(K+1)}(\sum_{u\in G}\pmb{h}_u^{(K)})\end{aligned}$$</p>
<p>其中$\pmb{h}_u^{(k)}$表示第$k$层GNN输出的顶点$u$的表征，$\pmb{h}_G$表示整张图的表征。$\pmb{h}_u^{(k)}$的计算过程称为聚合，$\pmb{h}_G$的计算过程称为读出。以往研究大多使用$\text{sum}$聚合与$\text{sum}$读出，而本文指出替换为另外的函数能够提升泛化性能。</p>
<h2 id="前馈网络mlps如何泛化">前馈网络MLPs如何泛化</h2>
<h3 id="relu-mlps的线性泛化">ReLU MLPs的线性泛化</h3>
<p>作者用下图呈现MLPs的泛化方式。灰色表示MLPs要学习的真实函数，蓝色和黑色分别表示模型在训练集和测试集上的预测。可以看到模型可以拟合训练集上的非线性函数，但脱离训练集后迅速变为线性函数。用数字来说，脱离训练集后MLPs预测的决定系数大于$0.99$。</p>
<img src="https://raw.githubusercontent.com/yliuhz/blogs/master/content/posts/iShot_2023-06-26_20.54.05.png" />
<p><strong>定理1</strong>（线性泛化）：假设在NTK机制下使用均方误差训练了一个两层MLP：$f:\mathbb{R}^d\to\mathbb{R}$。对于任意方向$\pmb{v}\in\mathbb{R}^d$，令$\pmb{x}_0=t\pmb{v}$，那么当$t\to\infty$时，$f(\pmb{x}_0+h\pmb{v})-f(\pmb{x}_0)\to\beta_vh$对任意的$h&gt;0$成立，$\beta_v$是常数。进一步地，给定$\epsilon&gt;0$，对于$t=O(\frac{1}{\epsilon})$，$|\frac{f(\pmb{x}_0+h\pmb{v})-f(\pmb{x}_0)}{h}-\beta_v|&lt;\epsilon$。</p>
<p>定理1说明了在训练数据集以外，ReLU MLPs可以拟合几乎线性的函数。对于二次函数（$\pmb{x}^TA\pmb{x}$）、余弦函数($\sum_{i=1}^d\cos(2\pi\cdot\pmb{x}^{(i)})$)、根次函数（$\sum_{i=1}^d\sqrt{\pmb{x}^{(i)}}$）等，ReLU MLPs不能泛化。
在合适的超参数下，MLPs可以正确地泛化L1范数，与定理1一致。如下图所示。</p>
<img src="https://raw.githubusercontent.com/yliuhz/blogs/master/content/posts/iShot_2023-06-30_11.13.51.png" />
<h3 id="relu-mlps什么时候一定provably可以泛化">ReLU MLPs什么时候一定（provably）可以泛化</h3>
<p>尽管上图显示MLPs对于线性函数可以较好地泛化，但这需要一定的条件，即训练数据集的分布必须足够“多样”。下面的引理1指出只需要$2d$条认真挑选的数据就可以实现ReLU MLPs的线性泛化。</p>
<p><strong>引理1</strong>：令$g(\pmb{x})=\pmb{\beta}^T\pmb{x}$表示待拟合的目标函数，$\pmb{\beta}\in\mathbb{R}^d$。假设数据集$\{\pmb{x}_i\}_{i=1}^n$包含正交基$\{\hat{\pmb{x}}_i\}_{i=1}^d$和$\{-\hat{\pmb{x}}_i\}_{i=1}^d$。若使用均方误差在$\{({\pmb{x}}_i,y_i)\}_{i=1}^n$上训练一个两层ReLU MLP，那么$f({\pmb{x}})={\pmb{\beta}}^T{\pmb{x}}$对任意的${\pmb{x}}\in\mathbb{R}^d$成立。</p>
<p>然而，仔细挑选出$2d$条符合条件的样本并不容易。下面的定理2基于更现实的场景，指出只要训练数据的分布包含所有的方向（例如一个包含原点的超球），那么在足够的训练数据量下MLP能够收敛到线性函数。</p>
<p><strong>定理2</strong>（泛化的条件）：令$g(\pmb{x})=\pmb{\beta}^T\pmb{x}$表示待拟合的目标函数，$\pmb{\beta}\in\mathbb{R}^d$。假设$\{\pmb{x}_i\}_{i=1}^n$从域$\mathcal{D}$中采样，其中$\mathcal{D}$包含一个连通的子集$S$，满足对任意非零向量$\pmb{w}\in\mathbb{R}^d$，存在$k&gt;0$使得$k\pmb{w}\in S$。若在NTK机制下，使用均方误差在$\{({\pmb{x}}_i,y_i)\}_{i=1}^n$上训练一个两层ReLU MLP，$f(\pmb{x})\xrightarrow{p}\pmb{\beta}^T\pmb{x}$在$n\to\infty$时成立，即$f$依概率收敛到$g$。</p>
<p>定理2说明了为什么数据集中“虚假”的相关性（真实不应存在的相关性）会损害模型的泛化性能，补充了因果推理的论点。例如，如果人工收集的训练图片中只有在沙漠中的骆驼，这里骆驼和沙漠就是数据集不够“多样”导致的虚假相关性，实际上骆驼还生活在草原等多种环境上。那么此时定理2的条件不再满足，模型也可能因此不能很好地泛化。</p>
<p>总的来说，定理1指出MLPs对于大多数非线性函数不能泛化，定理2指出MLPs当训练数据足够多样时能够在线性目标函数下泛化。</p>
<h3 id="使用其他激活函数的mlps">使用其他激活函数的MLPs</h3>
<p>以上讨论都基于使用ReLU激活函数的MLPs。除了ReLU，还有$\tanh(x),\cos(x),x^2$等激活函数。作者发现，在激活函数和待拟合的目标函数相近时，MLPs的泛化性能较好。</p>
<img src="https://raw.githubusercontent.com/yliuhz/blogs/master/content/posts/iShot_2023-07-03_15.36.11.png" />
<h2 id="图神经网络gnns如何泛化">图神经网络GNNs如何泛化</h2>
<p>以上讨论说明了MLPs在非线性任务上难以泛化。然而基于MLPs的GNNs却在一些非线性任务上表现出良好的泛化性，例如直观物理（intuitive Physics）、图论算法（graph algorithms）、符号数学（symbolic mathematics）等。</p>
<h3 id="一个假设线性对齐辅助了gnns的泛化">一个假设：线性对齐辅助了GNNs的泛化</h3>
<p>GNNs可以被用来解决<strong>最短路径</strong>问题。人们发现在GNN的聚合函数中使用最小$\min$函数后，训练后的GNN可以较好地泛化到比训练集更大的图上：</p>
<p>$$\pmb{h}_u^{(k)}=\min_{v\in\mathcal{N}(u)}\text{MLP}^{(k)}(\pmb{h}_u^{(k-1)},\pmb{h}_v^{(k-1)},\pmb{w}_{(v,u)})$$</p>
<p>另一方面，传统的最短路问题可以通过Bellman-Fold（BF）算法解决：</p>
<p>$$d[k][u]=\min_{v\in\mathcal{N}(u)}d[k-1][v]+\pmb{w}(v,u)$$</p>
<p>其中$\pmb{w}(v,u)$表示边$(v,u)$的权重，$d[k][u]$表示$k$步以内到达节点$u$的最短距离。可以发现BF算法的更新式子可以很容易地与GNN的更新式子对齐：只需令MLP学习一个线性函数$d[k-1][v]+\pmb{w}(v,u)$即可。由于MLPs可以较好地对线性目标函数泛化，所以GNNs可以在计算最短路径问题上良好地泛化。
反之，如果在GNN的聚合函数中使用$\text{sum}$或其他函数，那么MLP就需要学习一个非线性目标函数，导致其无法泛化（定理1），进而导致GNN无法泛化。</p>
<p>由上述最短路问题推广到其他问题，作者发现许多GNNs泛化性能好的问题都可以用动态规划（dynamic programming, DP）解决，而DP中的迭代更新式子与GNNs的特征聚合函数很相似。</p>
<p><strong>定义3</strong>：动态规划方法可以被形式化为：</p>
<p>$$\text{Answer}[k][s]=\text{DP-Update}(\{\text{Answer}[k-1][s&rsquo;],s&rsquo;=1,\cdots,n\})$$</p>
<p>其中$\text{Answer}[k][s]$表示第$k$次迭代、状态为$s$的子问题的解。</p>
<p><strong>假设1</strong>（线性算法对齐）：令$f:\mathcal{X}\to\mathbb{R}$表示目标函数。$\mathcal{N}$是一个神经网络，包含$m$个MLP模块。假设存在$m$个线性函数$\{g_i\}_{i=1}^m$，使得替换$\mathcal{N}$中的MLP后，$\mathcal{N}$能够模拟$f$。那么对于给定的$\epsilon&gt;0$，存在$\{(x_i,f(x_i))\}_{i=1}^n\subset\mathcal{D}\subsetneq\mathcal{X}$，使得在其上通过梯度下降和均方误差损失训练的$\mathcal{N}$得到的$\hat{f}$满足$\parallel\hat{f}-f\parallel&lt;\epsilon$。</p>
<p>作者认为，模型的线性对齐不局限于GNNs。人们可以将非线性的操作集成在模型的结构或者输入的表征向量中，这样在梯度下降训练时，模型只需要学习一个线性函数，从而提高了泛化能力。
GNNs学习DP的迭代表达式是一个例子，另外的例子是在算术任务中使用log-and-exp编码来提高乘法的泛化性。
另外，在一些任务中可能变换输入表征更容易。具体来说，目标函数$f$可以拆解为</p>
<p>$$f=g\circ h$$</p>
<p>其中$h$是表征向量，$g$是更简单的目标函数，例如线性函数，这样模型就更容易学习和泛化。对于表征向量$h$，可以使用领域知识；或者表征学习方法，在测试域$\mathcal{X}\setminus\mathcal{D}$进行无监督地表征学习。例如，在自然语言学习中，预训练表征和使用领域知识的特征转化可以帮助模型在不同语种之间泛化。在计量经济学中，人类对于本质因素或特征的判断（领域知识）尤其重要，因为金融市场经常需要模型进行泛化外推。</p>
<h3 id="理论推导和实验结果">理论推导和实验结果</h3>
<p>作者在3个DP任务上验证假设：最大度、最短路和$n$-body问题。首先，考虑计算图的最大度，可以通过1步DP解决。作为定理1的一个推论，使用$\text{sum}$聚合函数的GNNs无法在该问题上良好泛化。</p>
<p><strong>推论1</strong>：使用$\text{sum}$聚合和$\text{sum}$读出的GNNs在最大度问题上不能泛化。</p>
<p>利用假设1，为了实现线性对齐，将GNN的读出函数修改为$\max$函数。下面的定理3说明修改后的GNN能够良好地泛化。</p>
<p><strong>定理3</strong>（GNNs的泛化）：假设图中所有的顶点有相同的特征向量。令$g$和$g&rsquo;$分别表示最大度和最小度函数。令$\{(G_i,g(G_i))\}_{i=1}^n$表示训练集。如果$\{(g(G_i),g&rsquo;(G_i),g(G_i)\cdot N_i^{\max},g&rsquo;(G_i)\cdot N_i^{\min})\}_{i=1}^n$通过线性变换能表示$\mathbb{R}^4$（是$\mathbb{R}^4$的一组基），其中$N_i^{\max}$和$N_i^{\min}$分别表示$G_i$中具有最大度和最小度的顶点的个数，那么一个一层的使用$\max$读出函数的GNN，通过在$\{(G_i,g(G_i))\}_{i=1}^n$上使用均方误差损失和NTK机制训练，能够学习到目标函数$g$。</p>
<p>定理3中的条件与定理2类似，都是在保证训练集的多样性，只不过这里是用图的结构（即最大度）的多样性，而定理2中是用数据集的“方向”。如果训练集中所有的图有相同的最大度或者最小度，例如训练集仅仅属于path、$C$-regular graphs（度为$C$的正则图）、cycle、ladder四种类型之一，那么定理3的条件就遭到破坏，相应的GNN也不能保证学习到目标函数。</p>
<p>作者通过实验验证定理3和推论1。作者发现在最大度任务上，使用$\max$读出函数的GNN确实比使用$\text{sum}$读出函数的GNN的泛化效果要好；在最短路任务上，使用$\min$读出函数的GNN也确实比使用$\text{sum}$读出函数的GNN要好（图(a)）。
此外，在图(b)中，作者考虑第3个任务：$n$-body问题，即预测重力系统中$n$个物体随时间演变的规律。GNN的输入是完全图，每个顶点代表一个物体。顶点的特征由物体的质量$m_u$、在$t$时刻的位置$\pmb{x}_u^{(t)}$和速度$\pmb{v}_u^{(t)}$拼接而来。边特征设定为$0$。GNN的输出是在$t+1$时刻每个物体$u$的速度。真实的速度$f(G;u)$可以近似表示为</p>
<p>$$
\begin{aligned}
f(G;u)&amp;\approx\pmb{v}_u^t+\pmb{a}_u^t\cdot\text{d}t \\
\pmb{a}_u^t &amp;= C\cdot\sum_{v\neq u}\frac{m_v}{\parallel\pmb{x}_u^t-\pmb{x}_v^t\parallel_2^3}\cdot(\pmb{x}_v^t-\pmb{x}_u^t)
\end{aligned}
$$</p>
<p>其中$C$是常数。为了学习$f$，GNN中的MLP需要学习一个非线性函数，因此难以泛化。为了简化MLP的学习任务，使用表征$h(G)$替换输入的顶点特征。具体来说，将边特征由$0$替换为</p>
<p>$$\pmb{w}_{(u,v)}^{(t)}=m_v\cdot\frac{\pmb{x}_v^{(t)}-\pmb{x}_u^{(t)}}{\parallel\pmb{x}_u^t-\pmb{x}_v^t\parallel_2^3}$$</p>
<p>这样MLP只需要学习一个线性函数，从而提高了泛化能力。如下图(b)所示。</p>
<img src="https://raw.githubusercontent.com/yliuhz/blogs/master/content/posts/iShot_2023-07-04_11.59.54.png" />
<p>作者还发现训练图的结构也会对GNN的泛化能力造成影响，不同的任务中GNN更“喜欢”不同结构的训练图。如下图所示。</p>
<img src="https://raw.githubusercontent.com/yliuhz/blogs/master/content/posts/iShot_2023-07-04_11.59.59.png" />
<h2 id="本文与其他分布外问题设置的联系">本文与其他分布外问题设置的联系</h2>
<p><strong>领域自适应</strong>（domain adaptation）研究如何泛化到一个特定的目标域。典型的方法是在训练中加入目标域的无标签样本。</p>
<p><strong>自监督学习</strong>（self-supervised learning）研究如何在无标签样本上进行训练。</p>
<p><strong>不变模型</strong>（invariant models）研究如何在多种训练分布之间学习内在不变的本质特征。</p>
<p><strong>分布鲁棒性</strong>（distributional robustness）研究在数据分布上进行微小的对抗扰动，并保证模型在扰动后依然表现良好。</p>
<h2 id="总结">总结</h2>
<p>本文的核心思想是通过改进模型结构或者输入信息简化目标函数，从而提升泛化性能。
对于实际场景，真实的目标函数很可能是<strong>复杂且未知</strong>的，所以通过修改模型的结构达到提高泛化能力的方法可能不太容易。使用无监督表征方法改进输入的特征向量是不错的方法。</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Stochastic Blockmodels</title>
      <link>https://yliuhz.github.io/blogs/posts/sbm/</link>
      <pubDate>Wed, 21 Jun 2023 15:58:20 +0800</pubDate>
      
      <guid>https://yliuhz.github.io/blogs/posts/sbm/</guid>
      <description>本文基于 ( Citation: Karrer&amp;#32;&amp;amp;&amp;#32;Newman,&amp;#32;2011 Karrer,&amp;#32; B.&amp;#32;&amp;amp;&amp;#32;Newman,&amp;#32; M. &amp;#32; (2011). &amp;#32;Stochastic blockmodels and community structure in networks. Physical Review E,&amp;#32;83(1).&amp;#32;016107. https://doi.org/10.1103/PhysRevE.83.016107 ) 介绍社区发现中经典的随机块模型。 随机块模型是一种生成模型，它建模了社区与图生成之间的联系。尽管简单，随机块模型可以生成非常多样的图结构，包括同配图和异配图。
经典的随机块模型 考虑一个无向的多重图$G$，其中两个顶点之间的连边个数可以超过$1$。令$A_{ij}$表示图的邻接矩阵，当$i\neq j$时$A_{ij}$表示顶点$i$和$j$之间的连边个数，$i=j$时表示自环个数的2倍。 随机块模型假设不同边之间符合独立同泊松分布($P(x=k)=\frac{\lambda^k}{k!}\exp(-\lambda)$，期望为$\lambda$)。令$w_{rs}$表示社区$r$内的顶点和$s$内的顶点之间的期望连边个数，$\frac{1}{2}w_{rr}$表示社区$r$内部顶点之间的期望连边个数。令$g_i$表示顶点$i$的社区标签。拥有上述符号和独立性假设，我们可以写出图$G$的似然函数，即将所有边的存在概率相乘:
$$P(G|w,g)=\prod_{i&amp;lt;j}\frac{(w_{g_ig_j})^{A_{ij}}}{A_{ij}!}\exp(-w_{g_ig_j})\times \prod_i\frac{(\frac{1}{2}w_{g_ig_i})^{A_{ii}/2}}{(A_{ii}/2)!}\exp\left(-\frac{1}{2}w_{g_ig_i}\right)$$
做合并可以得到等价的表达：
$$P(G|w,g)=\frac{1}{\prod_{i&amp;lt;j}A_{ij}!\prod_i2^{A_{ii}/2}(A_{ii}/2)!}\prod_{rs}w_{rs}^{m_{rs}/2}\exp\left(-\frac{1}{2}n_rn_sw_{rs}\right)$$
其中$n_r$表示社区$r$内的顶点个数，$m_{rs}=\sum_{ij}A_{ij}\delta_{g_i,r}\delta_{g_j,s}$表示社区$r$和$s$之间的合计边个数，或者在$r=s$时等于该数值的二倍。
给定观测到的图结构，我们希望$w_{rs}$和$g_i$能够最大化这个似然函数。对似然函数取对数，并忽略掉与$w_{rs}$和$g_i$无关的常数(即前面带有$A_{ij}$的分式)，得到：
$$\log P(G|w,g)=\sum_{rs}(m_{rs}\log w_{rs}-n_rn_sw_{rs})$$
首先对$w_{rs}$求导，$\frac{\partial \log P}{\partial w_{rs}}=\sum_{rs}\left(\frac{m_{rs}}{w_{rs}}-n_rn_s\right)=0$，得到$w$的最优解：
$$\hat{w}_{rs}=\frac{m_{rs}}{n_rn_s},\forall r,s$$
将$\hat{w}_{rs}$带回对数似然，得到$\log P(G|\hat{w},g)=\sum_{rs}m_{rs}\log(m_{rs}/n_rn_s)-2m$，其中$m=\frac{1}{2}\sum_{rs}m_{rs}$表示图中所有连边的个数，与$g_i$无关可以丢掉，因此可以得到最终的对数似然优化目标：
$$\mathcal{L}(G|g)=\sum_{rs}m_{rs}\log\frac{m_{rs}}{n_rn_s}$$
所以，随机块模型定义了一个对数似然。 接下来，我们可以使用各种方法从$K^N$空间中采样$g$，并取使得$\mathcal{L}$最大的$g$作为社区发现的输出。
采样方法（社区发现方法） 方法1 ( Citation: Karrer&amp;#32;&amp;amp;&amp;#32;Newman,&amp;#32;2011 Karrer,&amp;#32; B.&amp;#32;&amp;amp;&amp;#32;Newman,&amp;#32; M. &amp;#32; (2011). &amp;#32;Stochastic blockmodels and community structure in networks. Physical Review E,&amp;#32;83(1).&amp;#32;016107. https://doi.org/10.1103/PhysRevE.83.016107 ) 中用自然语言描述了采样$g$的方法。首先随机地将图划分为$K$个社区（注意这里假设$K$是已知的）。接下来不断地将顶点移动到另一个使得$\mathcal{L}$增长最大的社区，或者减少最少的社区。当所有顶点移动一次后，检查移动过程中的$\mathcal{L}$值，取对应最大$\mathcal{L}$的移动结果作为下一次循环的开始状态。当$\mathcal{L}$无法被增长时算法停止。作者发现使用不同的随机种子多运行几次取最佳（$\mathcal{L}$最大的结果？）能够得到最好的结果。</description>
      <content:encoded><![CDATA[<p>本文基于 




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#1aq92btmc"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Brian"><span itemprop="familyName">Karrer</span></span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="M. E. J."><span itemprop="familyName">Newman</span></span>,&#32;<span itemprop="datePublished">2011</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Karrer</span>,&#32;
    <meta itemprop="givenName" content="Brian" />
    B.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Newman</span>,&#32;
    <meta itemprop="givenName" content="M. E. J." />
    M.</span>
  &#32;
    (<span itemprop="datePublished">2011</span>).
  &#32;<span itemprop="name">Stochastic blockmodels and community structure in networks</span>.<i>
    <span itemprop="about">Physical Review E</span>,&#32;83(1)</i>.&#32;<span itemprop="pagination">016107</span>.
  <a href="https://doi.org/10.1103/PhysRevE.83.016107"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.1103/PhysRevE.83.016107</a></span>




</span></span>)</span>
 介绍社区发现中经典的随机块模型。
随机块模型是一种生成模型，它建模了社区与图生成之间的联系。尽管简单，随机块模型可以生成非常多样的图结构，包括同配图和异配图。</p>
<h2 id="经典的随机块模型">经典的随机块模型</h2>
<p>考虑一个无向的多重图$G$，其中两个顶点之间的连边个数可以超过$1$。令$A_{ij}$表示图的邻接矩阵，当$i\neq j$时$A_{ij}$表示顶点$i$和$j$之间的连边个数，$i=j$时表示自环个数的2倍。
随机块模型假设不同边之间符合<strong>独立同泊松分布</strong>($P(x=k)=\frac{\lambda^k}{k!}\exp(-\lambda)$，期望为$\lambda$)。令$w_{rs}$表示社区$r$内的<strong>顶点</strong>和$s$内的<strong>顶点</strong>之间的期望连边个数，$\frac{1}{2}w_{rr}$表示社区$r$内部顶点之间的期望连边个数。令$g_i$表示顶点$i$的社区标签。拥有上述符号和独立性假设，我们可以写出图$G$的似然函数，即将所有边的存在概率相乘:</p>
<p>$$P(G|w,g)=\prod_{i&lt;j}\frac{(w_{g_ig_j})^{A_{ij}}}{A_{ij}!}\exp(-w_{g_ig_j})\times \prod_i\frac{(\frac{1}{2}w_{g_ig_i})^{A_{ii}/2}}{(A_{ii}/2)!}\exp\left(-\frac{1}{2}w_{g_ig_i}\right)$$</p>
<p>做合并可以得到等价的表达：</p>
<p>$$P(G|w,g)=\frac{1}{\prod_{i&lt;j}A_{ij}!\prod_i2^{A_{ii}/2}(A_{ii}/2)!}\prod_{rs}w_{rs}^{m_{rs}/2}\exp\left(-\frac{1}{2}n_rn_sw_{rs}\right)$$</p>
<p>其中$n_r$表示社区$r$内的顶点个数，$m_{rs}=\sum_{ij}A_{ij}\delta_{g_i,r}\delta_{g_j,s}$表示社区$r$和$s$之间的合计边个数，或者在$r=s$时等于该数值的二倍。</p>
<p>给定观测到的图结构，我们希望$w_{rs}$和$g_i$能够最大化这个似然函数。对似然函数取对数，并忽略掉与$w_{rs}$和$g_i$无关的常数(即前面带有$A_{ij}$的分式)，得到：</p>
<p>$$\log P(G|w,g)=\sum_{rs}(m_{rs}\log w_{rs}-n_rn_sw_{rs})$$</p>
<p>首先对$w_{rs}$求导，$\frac{\partial \log P}{\partial w_{rs}}=\sum_{rs}\left(\frac{m_{rs}}{w_{rs}}-n_rn_s\right)=0$，得到$w$的最优解：</p>
<p>$$\hat{w}_{rs}=\frac{m_{rs}}{n_rn_s},\forall r,s$$</p>
<p>将$\hat{w}_{rs}$带回对数似然，得到$\log P(G|\hat{w},g)=\sum_{rs}m_{rs}\log(m_{rs}/n_rn_s)-2m$，其中$m=\frac{1}{2}\sum_{rs}m_{rs}$表示图中所有连边的个数，与$g_i$无关可以丢掉，因此可以得到最终的对数似然优化目标：</p>
<p>$$\mathcal{L}(G|g)=\sum_{rs}m_{rs}\log\frac{m_{rs}}{n_rn_s}$$</p>
<p>所以，随机块模型定义了一个对数似然。
接下来，我们可以使用各种方法从$K^N$空间中采样$g$，并取使得$\mathcal{L}$最大的$g$作为社区发现的输出。</p>
<h2 id="采样方法社区发现方法">采样方法（社区发现方法）</h2>
<h4 id="方法1">方法1</h4>
<p>




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#1aq92btmc"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Brian"><span itemprop="familyName">Karrer</span></span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="M. E. J."><span itemprop="familyName">Newman</span></span>,&#32;<span itemprop="datePublished">2011</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Karrer</span>,&#32;
    <meta itemprop="givenName" content="Brian" />
    B.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Newman</span>,&#32;
    <meta itemprop="givenName" content="M. E. J." />
    M.</span>
  &#32;
    (<span itemprop="datePublished">2011</span>).
  &#32;<span itemprop="name">Stochastic blockmodels and community structure in networks</span>.<i>
    <span itemprop="about">Physical Review E</span>,&#32;83(1)</i>.&#32;<span itemprop="pagination">016107</span>.
  <a href="https://doi.org/10.1103/PhysRevE.83.016107"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.1103/PhysRevE.83.016107</a></span>




</span></span>)</span>
 中用自然语言描述了采样$g$的方法。首先随机地将图划分为$K$个社区（注意这里假设$K$是已知的）。接下来不断地将顶点移动到另一个使得$\mathcal{L}$增长最大的社区，或者减少最少的社区。当所有顶点移动一次后，检查移动过程中的$\mathcal{L}$值，取对应最大$\mathcal{L}$的移动结果作为下一次循环的开始状态。当$\mathcal{L}$无法被增长时算法停止。作者发现使用不同的随机种子多运行几次取最佳（$\mathcal{L}$最大的结果？）能够得到最好的结果。</p>
<h4 id="方法2">方法2</h4>
<p>另一篇




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#h0sxwtcp"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Xiaoyan"><span itemprop="familyName">Lu</span></span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Boleslaw K."><span itemprop="familyName">Szymanski</span></span>,&#32;<span itemprop="datePublished">2019</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Lu</span>,&#32;
    <meta itemprop="givenName" content="Xiaoyan" />
    X.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Szymanski</span>,&#32;
    <meta itemprop="givenName" content="Boleslaw K." />
    B.</span>
  &#32;
    (<span itemprop="datePublished">2019</span>).
  &#32;<span itemprop="name">A Regularized Stochastic Block Model for the robust community detection in complex networks</span>.<i>
    <span itemprop="about">Scientific Reports</span>,&#32;9(1)</i>.&#32;<span itemprop="pagination">13247</span>.
  <a href="https://doi.org/10.1038/s41598-019-49580-5"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.1038/s41598-019-49580-5</a></span>




</span></span>)</span>
 在<a href="https://doi.org/10.1038/s41598-019-49580-5">Supplementary information</a>中使用了另一种采样方法。初始时仍然是随机地将顶点指定到$K$个社区中的任意一个。接下来，尝试以一定的概率将顶点从社区$r$转移到社区$s$：</p>
<p>$$p(r\to s|t)=\frac{m_{ts}+\epsilon}{\sum_sm_{ts}+\epsilon K}$$</p>
<p>其中$t$表示顶点的邻居的社区标签，$m_{ts}$表示社区$t$和$s$之间的合计边个数，或者在$t=s$时等于该数值的二倍。$\epsilon&gt;0$通常被设置成较小的数值，在$\epsilon$趋于无穷时转化概率变为$1/K$成为完全随机地转移。对于每次尝试转移，接受该转移的概率$a$定义为：</p>
<p>$$a=\min \left\{\exp(\beta\Delta\mathcal{L})\frac{\sum_tn_tp(s\to r|t)}{\sum_tn_tp(r\to s|t)},1\right\}$$</p>
<p>其中转移完成后该顶点有$n_t$个邻居属于社区$t$，$\Delta\mathcal{L}$表示每次转移后对数似然的变化，$p(s\to r|t)$在顶点进行$r\to s$的转移后进行计算。$\beta$是温度参数，可以防止陷入局部最优（<a href="https://doi.org/10.1038/s41598-019-49580-5">Supplementary information</a>中的式子疑似有误，比如$\min$函数里没有$1$，没有温度参数，根据




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#1p6rfctx"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Tiago P."><span itemprop="familyName">Peixoto</span></span>,&#32;<span itemprop="datePublished">2014</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Peixoto</span>,&#32;
    <meta itemprop="givenName" content="Tiago P." />
    T.</span>
  &#32;
    (<span itemprop="datePublished">2014</span>).
  &#32;<span itemprop="name">Efficient Monte Carlo and greedy heuristic for the inference of stochastic block models</span>.<i>
    <span itemprop="about">Physical Review E</span>,&#32;89(1)</i>.&#32;<span itemprop="pagination">012804</span>.
  <a href="https://doi.org/10.1103/PhysRevE.89.012804"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.1103/PhysRevE.89.012804</a></span>




</span></span>)</span>
进行了修改）。</p>
<h2 id="随机块模型与模块度的联系">随机块模型与模块度的联系</h2>
<p>随机块模型的优化目标是对数似然，而一些热门的社区发现算法，如Louvain方法 




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#2hxkuyg3"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Vincent D"><span itemprop="familyName">Blondel</span></span>,&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Jean-Loup"><span itemprop="familyName">Guillaume</span></span>
                  <em>&amp; al.</em>,&#32;<span itemprop="datePublished">2008</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Blondel</span>,&#32;
    <meta itemprop="givenName" content="Vincent D" />
    V.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Guillaume</span>,&#32;
    <meta itemprop="givenName" content="Jean-Loup" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Lambiotte</span>,&#32;
    <meta itemprop="givenName" content="Renaud" />
    R.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Lefebvre</span>,&#32;
    <meta itemprop="givenName" content="Etienne" />
    E.</span>
  &#32;
    (<span itemprop="datePublished">2008</span>).
  &#32;<span itemprop="name">Fast unfolding of communities in large networks</span>.<i>
    <span itemprop="about">Journal of Statistical Mechanics: Theory and Experiment</span>,&#32;2008(10)</i>.&#32;<span itemprop="pagination">P10008</span>.
  <a href="https://doi.org/10.1088/1742-5468/2008/10/P10008"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.1088/1742-5468/2008/10/P10008</a></span>




</span></span>)</span>
 等，采用模块度 




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#uqjs6e0v"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="M. E. J."><span itemprop="familyName">Newman</span></span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="M."><span itemprop="familyName">Girvan</span></span>,&#32;<span itemprop="datePublished">2004</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Newman</span>,&#32;
    <meta itemprop="givenName" content="M. E. J." />
    M.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Girvan</span>,&#32;
    <meta itemprop="givenName" content="M." />
    M.</span>
  &#32;
    (<span itemprop="datePublished">2004</span>).
  &#32;<span itemprop="name">Finding and evaluating community structure in networks</span>.<i>
    <span itemprop="about">Physical Review E</span>,&#32;69(2)</i>.&#32;<span itemprop="pagination">026113</span>.
  <a href="https://doi.org/10.1103/PhysRevE.69.026113"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.1103/PhysRevE.69.026113</a></span>




</span></span>)</span>
 作为优化目标。对数似然和模块度实际上存在联系。</p>
<p>将随机块模型的对数似然式子等价变换，得到</p>
<p>$$\mathcal{L}(G|g)=\sum_{rs}\frac{m_{rs}}{2m}\log\frac{m_{rs}/2m}{n_rn_s/n^2}$$</p>
<p>上式中仅添加了顶点个数$n$和边个数$m$，对于优化来说没有影响。式中有两个概率表达式：$m_{rs}/2m$和$n_rn_s/n^2$。其中，$m_{rs}/2m$表示随机采样一条边落在社区$r$和$s$之间的概率；$n_rn_s/n^2$可以看作当图中有$n^2/2$条边时的这个概率。将上述两个概率分布分别记作$p_K(r,s)$和$p_1(r,s)$，则对数似然可以被重写为</p>
<p>$$\mathcal{L}(G|g)=\sum_{rs}p_K(r,s)\log\frac{p_K(r,s)}{p_1(r,s)}$$</p>
<p>成为$p_K$和$p_1$的KL-散度。</p>
<p>这种定义一个空模型（null model）$p_1$的思想在模块度中也有体现：</p>
<p>$$Q(g)=\frac{1}{2m}\sum_{ij}[A_{ij}-P_{ij}]\delta(g_i,g_j)$$</p>
<p>其中$A_{ij}$表示邻接矩阵在$i,j$处的值，$P_{ij}$表示在空模型下这个值的期望。如果在模块度中使用对数似然的空模型$p_1$，那么模块度的表达式转化为：</p>
<p>$$Q(g)=\sum_{r=1}^K[p_K(r,r)-p_1(r,r)]$$</p>
<p>然而，$p_1$的最大问题是不符合实际观测到的图结构，它没有保护观测图中的顶点的度，因此实际应用中通常不会使用。如果能够保证空模型中顶点度的期望与观测图相同，那么新的空模型可以表示为</p>
<p>$$p_{degree}(r,s)=\frac{\kappa_r}{2m}\frac{\kappa_s}{2m}$$</p>
<p>其中$\kappa_r=\sum_sm_{rs}=\sum_ik_i\delta_{g_i,r}$表示社区$r$中所有顶点的度之和。（也可以从另一角度理解$\kappa_r$：将原图中所有的边切成两半准备重新随机连接，那么$\kappa_r$表示从社区$r$中伸出的半边（stub）的个数。）这样新的模块度转化为：</p>
<p>$$Q(g)=\sum_{r=1}^K[p_K(r,r)-p_{degree}(r,r)]$$</p>
<p>新的空模型$p_{degree}$导出的模块度优化目标的效果更好。这是因为具有高度数的顶点本就应有更高的概率相连，因为它们能伸出更多的半边。</p>
<p>受模块度的启发，作者 




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#1aq92btmc"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Brian"><span itemprop="familyName">Karrer</span></span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="M. E. J."><span itemprop="familyName">Newman</span></span>,&#32;<span itemprop="datePublished">2011</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Karrer</span>,&#32;
    <meta itemprop="givenName" content="Brian" />
    B.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Newman</span>,&#32;
    <meta itemprop="givenName" content="M. E. J." />
    M.</span>
  &#32;
    (<span itemprop="datePublished">2011</span>).
  &#32;<span itemprop="name">Stochastic blockmodels and community structure in networks</span>.<i>
    <span itemprop="about">Physical Review E</span>,&#32;83(1)</i>.&#32;<span itemprop="pagination">016107</span>.
  <a href="https://doi.org/10.1103/PhysRevE.83.016107"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.1103/PhysRevE.83.016107</a></span>




</span></span>)</span>
 提出将顶点度的异构性集成到对数似然中，能得到更好的随机块模型。</p>
<h2 id="度保护随机块模型">度保护随机块模型</h2>
<p>在经典的随机块模型中，使用$w_{g_ig_j}$刻画社区$g_i$和$g_j$之间边的期望个数，没有对社区$g_i$和$g_j$内的顶点进行区分。在新的度保护随机块模型中，引入新的变量$\theta$，其中$\theta_i$控制顶点$i$的平均度数，这样对一个观测到的图$G$，新的似然函数为：</p>
<p>$$P(G|\theta,w,g)=\prod_{i&lt;j}\frac{(\theta_i\theta_jw_{g_ig_j})^{A_{ij}}}{A_{ij}!}\exp(-\theta_i\theta_jw_{g_ig_j})\times \prod_i\frac{(\frac{1}{2}\theta_i^2w_{g_ig_i})^{A_{ii}/2}}{(A_{ii}/2)!}\exp\left(-\frac{1}{2}\theta_i^2w_{g_ig_i}\right)$$</p>
<p>其中$\theta_i$作了<strong>归一化</strong>：$\sum_i\theta_i\delta_{g_i,r}=1$。这样$\theta_i$不再表示顶点$i$度数的期望，而是表示当一条边连向社区$g_i$时，具体连向这个顶点$i$的概率。与经典随机块模型类似，对似然函数进行等价重写：</p>
<p>$$P(G|\theta,w,g)=\frac{1}{\prod_{i&lt;j}A_{ij}!\prod_i2^{A_{ii}/2}(A_{ii}/2)!}\prod_i\theta_i^{k_i}\prod_{rs}w_{rs}^{m_{rs}/2}\exp\left(-\frac{1}{2}w_{rs}\right)$$</p>
<p>其中$k_i$表示顶点$i$的度数。由于$\theta_i$作了归一化，$\exp$函数内不再包含$n_rn_s$。对似然函数取对数，并忽略掉与变量无关的常数：</p>
<p>$$\log P(G|\theta,w,g)=2\sum_ik_i\log\theta_i+\sum_{rs}(m_{rs}\log w_{rs}-w_{rs})$$</p>
<p>首先观察到对数似然关于$\theta_i$是递增函数，而$\theta_i$有归一化限制，且$\theta_i&gt;0$，因此$\theta_i$的极值点为</p>
<p>$$\hat{\theta}_i=\frac{k_i}{\kappa_{g_i}}$$</p>
<p>然后对$w$求偏导，得到$w_{rs}$的极值点为</p>
<p>$$\hat{w}_{rs}=m_{rs}$$</p>
<p>将$\hat{\theta_i}$和$\hat{w}_{rs}$代入对数似然中，得到</p>
<p>$$\log P(G|\theta,w,g)=2\sum_ik_i\log\frac{k_i}{\kappa_{g_i}}+\sum_{rs}m_{rs}\log m_{rs}-2m$$</p>
<p>作者利用$\kappa_r=\sum_sm_{rs}=\sum_ik_i\delta_{g_i,r}$对第一项做了巧妙的等价变换：</p>
<p>$$\begin{aligned}
2\sum_ik_i\log\frac{k_i}{\kappa_{g_i}}
&amp;= 2\sum_ik_i\log k_i-2\sum_ik_i\log \kappa_{g_i}  \\
&amp;= 2\sum_ik_i\log k_i-2\sum_i\sum_rk_i\delta_{g_i,r}\log \kappa_r \\
&amp;= 2\sum_ik_i\log k_i-2\sum_r\sum_ik_i\delta_{g_i,r}\log \kappa_r \\
&amp;= 2\sum_ik_i\log k_i-2\sum_r\kappa_r\log\kappa_r \\
&amp;= 2\sum_ik_i\log k_i-(\sum_r\kappa_r\log\kappa_r+\sum_s\kappa_s\log\kappa_s) \\
&amp;= 2\sum_ik_i\log k_i-(\sum_{rs}m_{rs}\log\kappa_r+\sum_{sr}m_{rs}\log\kappa_s) \\
&amp;= 2\sum_ik_i\log k_i-\sum_{rs}m_{rs}\log\kappa_r\kappa_s
\end{aligned}$$</p>
<p>代入对数似然中，并丢弃与$g$无关的常数（$k_i,m$），得到：</p>
<p>$$\mathcal{L}(G|g)=\sum_{rs}m_{rs}\log\frac{m_{rs}}{\kappa_r\kappa_s}$$</p>
<p>可以看到，经过推导新的对数似然与经典的对数似然只有很小的差别。但是新的对数似然已经转化为$p_K$和$p_{degree}$的KL-散度，即</p>
<p>$$\mathcal{L}(G|g)=\sum_{rs}\frac{m_{rs}}{2m}\log\frac{m_{rs}/2m}{(\kappa_r/2m)(\kappa_s/2m)}$$</p>
<p>换句话说，新的对数似然找到的是与给定顶点度的随机图差别最大的社区划分，而经典的对数似然找到的是与完全随机图差别最大的社区划分。</p>
<h2 id="正则随机块模型">正则随机块模型</h2>
<p>研究者发现 




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#h0sxwtcp"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Xiaoyan"><span itemprop="familyName">Lu</span></span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Boleslaw K."><span itemprop="familyName">Szymanski</span></span>,&#32;<span itemprop="datePublished">2019</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Lu</span>,&#32;
    <meta itemprop="givenName" content="Xiaoyan" />
    X.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Szymanski</span>,&#32;
    <meta itemprop="givenName" content="Boleslaw K." />
    B.</span>
  &#32;
    (<span itemprop="datePublished">2019</span>).
  &#32;<span itemprop="name">A Regularized Stochastic Block Model for the robust community detection in complex networks</span>.<i>
    <span itemprop="about">Scientific Reports</span>,&#32;9(1)</i>.&#32;<span itemprop="pagination">13247</span>.
  <a href="https://doi.org/10.1038/s41598-019-49580-5"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.1038/s41598-019-49580-5</a></span>




</span></span>)</span>
 在拟合度保护随机块模型时，模型可能随机地收敛到同配或异配的社区结构，这可能不是数据挖掘用户所期望的。因此，作者提出用一个参数来限定随机块模型的输出。</p>
<h3 id="前置实验">前置实验</h3>
<p>作者做了一个实验。首先使用度保护随机块模型生成一个图，其中</p>
<p>$$w_{rs}=
\begin{cases}
\gamma w_0, &amp; \text{if } r=s \\
w_0, &amp; \text{if } r\neq s
\end{cases}
$$</p>
<p>其中$\gamma$越大会生成结构越同配（assortative）的图结构，$w_0$控制了图的稀疏程度。实验中，$\gamma$取$10$，$w_0$取$0.01$，顶点度序列$\{k_i\}$由参数为$2.5$的指数分布生成，社区个数为$2$，每个社区包含$10$个顶点。使用MCMC方法（采样方法2）进行采样。在$20$次采样中，模型只有$1$次收敛到同配的局部最优解，其余$19$次均收敛到异配的局部最优解。如下图所示。</p>
<img src="https://raw.githubusercontent.com/yliuhz/blogs/master/content/posts/iShot_2023-07-05_10.52.32.png" />
<h3 id="改进方法">改进方法</h3>
<p>回顾度保护随机块模型中，泊松分布的均值定义为$\lambda_{ij}=\theta_i\theta_jw_{g_ig_j}$。作者将其重新定义为</p>
<p>$$\lambda_{ij}=
\begin{cases}
w_{g_ig_j}I_iI_j, &amp; \text{if } g_i=g_j \\
w_{g_ig_j}O_iO_j, &amp; \text{if } g_i\neq g_j
\end{cases}
$$</p>
<p>回顾对数似然$\log(G|\{\lambda_{ij}\})=\frac{1}{2}\sum_{ij}(A_{ij}\log\lambda_{ij}-\lambda_{ij})$，代入新定义的$\lambda_{ij}$，得到</p>
<p>$$\mathcal{L}(G|g,w,I,O)=2\sum_i(k_i^+\log I_i+k_i^-\log O_i)+\sum_{rs}m_{rs}\log w_{rs}-w_{rs}\Lambda_{rs}$$</p>
<p>其中$k_i^+$表示节点$i$在其社区内部的度，$k_i^-=k_i-k_i^+$，$\Lambda_{rs}$为</p>
<p>$$\Lambda_{rs}=
\begin{cases}
(\sum_{i\in r}I_i)^2, &amp; \text{if } r=s \\
\sum_{i\in r}O_i\sum_{j\in s}O_j, &amp; \text{if }r\neq s
\end{cases}
$$</p>
<p>其中$i\in r$表示$i\in g_i$。</p>
<p>计算$w_{rs}$的极值，得到$\hat{w}_{rs}=\frac{m_{rs}}{\Lambda_{rs}}$，代入对数似然，得到</p>
<p>$$\mathcal{L}(G|g,I,O)=\sum_{rs}m_{rs}\log\frac{m_{rs}}{\lambda_{rs}}+2\sum_i(k_i^+\log I_i+k_i^-\log O_i)$$</p>
<p>定义一个先验参数$f_i=\frac{I_i}{I_i+O_i}$，$\theta_i=I_i+O_i$，那么上述对数似然可以重写为</p>
<p>$$\mathcal{L}(G|g,I,O)=\sum_{rs}m_{rs}\log\frac{m_{rs}}{\lambda_{rs}}-2\sum_ik_iH(\frac{k_i^+}{k_i},f_i)+2\sum_ik_i\log\theta_i$$</p>
<p>其中$H(\frac{k_i^+}{k_i},f_i)=-\frac{k_i^+}{k_i}\log f_i-\frac{k_i^-}{k_i}\log(1-f_i)$表示观测到的$\frac{k_i^+}{k_i}$与先验$f_i$的交叉熵。因此，最大化该对数似然也是在最小化观测和先验的差距。$\frac{k_i^+}{k_i}$表示顶点$i$连接同社区邻居个数占其所有邻居个数的比例。</p>
<p>假设先验函数$f$只与顶点度有关，即$f_i=f(k_i)$，那么$f(k):\mathbb{Z}_+\to[0,1]$应是严格递减的函数。对于同配的社区划分，我们有</p>
<ul>
<li>$f(1)=1$，因为只有一个邻居的顶点一定属于它连接的那个社区；</li>
<li>对于$k\approx|V|$，有$f(k)\ll 1$，因为一个中心顶点最终不归属于任何社区。</li>
</ul>
<p>作者给出了$f$的一些例子，如</p>
<ul>
<li>$f(k)=\alpha+\frac{1-\alpha}{k}$，</li>
<li>$f(k)=\max\{f, \frac{1}{k}\}$。</li>
</ul>
<h3 id="实验">实验</h3>
<p>首先是之前的$20$个顶点的合成数据集的对比。可以发现使用正则随机块模型后，$20$次MCMC均收敛到同配的社区结构。</p>
<img src="https://raw.githubusercontent.com/yliuhz/blogs/master/content/posts/iShot_2023-07-05_12.09.17.png" />
<p>在Karate club network 真实数据集上，设定$\theta_i=k_i,f(k_i)=\max\{f, \frac{1}{k_i}\}$。使用不同的$f$可以控制输出社区的同配性。如下图所示。</p>
<img src="https://raw.githubusercontent.com/yliuhz/blogs/master/content/posts/iShot_2023-07-05_12.08.49.png" />
<h3 id="rsbm的性质">RSBM的性质</h3>
<p><strong>定理1</strong>：当对于任意顶点$i$，$f_i=1/2$时，RSBM的MLE与DCSBM的MLE相同。</p>
<p><strong>定理2</strong>：对于任意自定义的$\{f_i\}$和极大似然估计的结果$\hat{\theta}_i$，RSBM能够保护顶点的度，即</p>
<p>$$\sum_j\lambda_{ij}=k_i$$</p>
<p><strong>定理3</strong>：当对于任意顶点$i$，$\theta_i=k_i$时，最大化RSBM的对数似然等价于最大化</p>
<p>$$\mathcal{L}=D_{KL}(p_{degree}(r,s)||p_{null}(r,s))-2\mathbb{E}_{k_i}[H(\frac{k_i^+}{k_i})]$$</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Structural Community Detection</title>
      <link>https://yliuhz.github.io/blogs/posts/cd/</link>
      <pubDate>Mon, 19 Jun 2023 10:55:48 +0800</pubDate>
      
      <guid>https://yliuhz.github.io/blogs/posts/cd/</guid>
      <description>本文专注于解释社区发现的两个经典算法：Louvain方法和Infomap方法。
问题定义 给定一个图$G=(V,E)$，找到一个映射$g:V\to {1,2,\cdots,K}$，$g$将图中的顶点映射到社区标签。
Louvain方法 Louvain方法 ( Citation: Blondel,&amp;#32;Guillaume &amp;amp; al.,&amp;#32;2008 Blondel,&amp;#32; V.,&amp;#32; Guillaume,&amp;#32; J.,&amp;#32; Lambiotte,&amp;#32; R.&amp;#32;&amp;amp;&amp;#32;Lefebvre,&amp;#32; E. &amp;#32; (2008). &amp;#32;Fast unfolding of communities in large networks. Journal of Statistical Mechanics: Theory and Experiment,&amp;#32;2008(10).&amp;#32;P10008. https://doi.org/10.1088/1742-5468/2008/10/P10008 ) 是一种贪心算法，其优化目标是模块度，如下式所示：
$$Q=\frac{1}{2m}\sum_{i,j}\left[A_{ij}-\frac{k_ik_j}{2m}\right]\delta(c_i,c_j)$$
其中$A_{ij}$表示顶点$i$和顶点$j$之间连边的权重；$k_i=\sum_jA_{ij}$表示与顶点$i$相连的边的权重之和；$c_i$表示顶点$i$的社区标签；$\delta(u,v)$在$u=v$时等于1，否则等于0；$m=\frac{1}{2}\sum_{ij}A_{ij}$。
Louvain算法分为两阶段。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 初始时设定每个顶点独立属于一个社区 # 第一阶段 生成一个随机的顶点序列Queue For each node i in Queue: For each neighbor j of i: 尝试将i的社区标签c_i修改为j的社区标签c_j 计算模块度的增长DQ If max(DQ)&amp;gt;0: 修改i的社区标签 Else: 保持i的社区标签不变 # 第二阶段 For each community c_i in G: 将社区标签为c_i的所有顶点聚合为一个新的顶点 原c_i内的连边转化为新顶点的自环，边权为原边权之和 原c_i内顶点与另一社区c_j内顶点的所有连边聚合为一条连边，边权为原边权之和 # 重新执行第一阶段，直到模块度Q不再增加 第一阶段中顶点序列的顺序会影响算法的输出。作者发现不同的顶点处理顺序会影响算法的时间效率，但不会对最终的模块度造成过大（significant）的影响。</description>
      <content:encoded><![CDATA[<p>本文专注于解释社区发现的两个经典算法：Louvain方法和Infomap方法。</p>
<h2 id="问题定义">问题定义</h2>
<p>给定一个图$G=(V,E)$，找到一个映射$g:V\to {1,2,\cdots,K}$，$g$将图中的顶点映射到社区标签。</p>
<h2 id="louvain方法">Louvain方法</h2>
<p>Louvain方法 




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#2hxkuyg3"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Vincent D"><span itemprop="familyName">Blondel</span></span>,&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Jean-Loup"><span itemprop="familyName">Guillaume</span></span>
                  <em>&amp; al.</em>,&#32;<span itemprop="datePublished">2008</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Blondel</span>,&#32;
    <meta itemprop="givenName" content="Vincent D" />
    V.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Guillaume</span>,&#32;
    <meta itemprop="givenName" content="Jean-Loup" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Lambiotte</span>,&#32;
    <meta itemprop="givenName" content="Renaud" />
    R.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Lefebvre</span>,&#32;
    <meta itemprop="givenName" content="Etienne" />
    E.</span>
  &#32;
    (<span itemprop="datePublished">2008</span>).
  &#32;<span itemprop="name">Fast unfolding of communities in large networks</span>.<i>
    <span itemprop="about">Journal of Statistical Mechanics: Theory and Experiment</span>,&#32;2008(10)</i>.&#32;<span itemprop="pagination">P10008</span>.
  <a href="https://doi.org/10.1088/1742-5468/2008/10/P10008"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.1088/1742-5468/2008/10/P10008</a></span>




</span></span>)</span>
 是一种贪心算法，其优化目标是模块度，如下式所示：</p>
<p>$$Q=\frac{1}{2m}\sum_{i,j}\left[A_{ij}-\frac{k_ik_j}{2m}\right]\delta(c_i,c_j)$$</p>
<p>其中$A_{ij}$表示顶点$i$和顶点$j$之间连边的权重；$k_i=\sum_jA_{ij}$表示与顶点$i$相连的边的权重之和；$c_i$表示顶点$i$的社区标签；$\delta(u,v)$在$u=v$时等于1，否则等于0；$m=\frac{1}{2}\sum_{ij}A_{ij}$。</p>
<p>Louvain算法分为两阶段。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt" id="hl-0-1"><a class="lnlinks" href="#hl-0-1"> 1</a>
</span><span class="lnt" id="hl-0-2"><a class="lnlinks" href="#hl-0-2"> 2</a>
</span><span class="lnt" id="hl-0-3"><a class="lnlinks" href="#hl-0-3"> 3</a>
</span><span class="lnt" id="hl-0-4"><a class="lnlinks" href="#hl-0-4"> 4</a>
</span><span class="lnt" id="hl-0-5"><a class="lnlinks" href="#hl-0-5"> 5</a>
</span><span class="lnt" id="hl-0-6"><a class="lnlinks" href="#hl-0-6"> 6</a>
</span><span class="lnt" id="hl-0-7"><a class="lnlinks" href="#hl-0-7"> 7</a>
</span><span class="lnt" id="hl-0-8"><a class="lnlinks" href="#hl-0-8"> 8</a>
</span><span class="lnt" id="hl-0-9"><a class="lnlinks" href="#hl-0-9"> 9</a>
</span><span class="lnt" id="hl-0-10"><a class="lnlinks" href="#hl-0-10">10</a>
</span><span class="lnt" id="hl-0-11"><a class="lnlinks" href="#hl-0-11">11</a>
</span><span class="lnt" id="hl-0-12"><a class="lnlinks" href="#hl-0-12">12</a>
</span><span class="lnt" id="hl-0-13"><a class="lnlinks" href="#hl-0-13">13</a>
</span><span class="lnt" id="hl-0-14"><a class="lnlinks" href="#hl-0-14">14</a>
</span><span class="lnt" id="hl-0-15"><a class="lnlinks" href="#hl-0-15">15</a>
</span><span class="lnt" id="hl-0-16"><a class="lnlinks" href="#hl-0-16">16</a>
</span><span class="lnt" id="hl-0-17"><a class="lnlinks" href="#hl-0-17">17</a>
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">初始时设定每个顶点独立属于一个社区
</span></span><span class="line"><span class="cl"># 第一阶段
</span></span><span class="line"><span class="cl">生成一个随机的顶点序列Queue
</span></span><span class="line"><span class="cl">For each node i in Queue:
</span></span><span class="line"><span class="cl">    For each neighbor j of i:
</span></span><span class="line"><span class="cl">        尝试将i的社区标签c_i修改为j的社区标签c_j
</span></span><span class="line"><span class="cl">        计算模块度的增长DQ
</span></span><span class="line"><span class="cl">    If max(DQ)&gt;0:
</span></span><span class="line"><span class="cl">        修改i的社区标签
</span></span><span class="line"><span class="cl">    Else:
</span></span><span class="line"><span class="cl">        保持i的社区标签不变
</span></span><span class="line"><span class="cl"># 第二阶段
</span></span><span class="line"><span class="cl">For each community c_i in G:
</span></span><span class="line"><span class="cl">    将社区标签为c_i的所有顶点聚合为一个新的顶点
</span></span><span class="line"><span class="cl">    原c_i内的连边转化为新顶点的自环，边权为原边权之和
</span></span><span class="line"><span class="cl">    原c_i内顶点与另一社区c_j内顶点的所有连边聚合为一条连边，边权为原边权之和
</span></span><span class="line"><span class="cl"># 重新执行第一阶段，直到模块度Q不再增加
</span></span></code></pre></td></tr></table>
</div>
</div><p>第一阶段中顶点序列的顺序会影响算法的输出。作者发现不同的顶点处理顺序会影响算法的时间效率，但不会对最终的模块度造成过大（significant）的影响。</p>
<h2 id="infomap方法">Infomap方法</h2>
<p>Infomap方法 




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#umb3jcfk"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="M."><span itemprop="familyName">Rosvall</span></span>,&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="D."><span itemprop="familyName">Axelsson</span></span>
                  <em>&amp; al.</em>,&#32;<span itemprop="datePublished">2009</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Rosvall</span>,&#32;
    <meta itemprop="givenName" content="M." />
    M.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Axelsson</span>,&#32;
    <meta itemprop="givenName" content="D." />
    D.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Bergstrom</span>,&#32;
    <meta itemprop="givenName" content="C. T." />
    C.</span>
  &#32;
    (<span itemprop="datePublished">2009</span>).
  &#32;<span itemprop="name">The map equation</span>.<i>
    <span itemprop="about">The European Physical Journal Special Topics</span>,&#32;178(1)</i>.&#32;<span itemprop="pagination">13–23</span>.
  <a href="https://doi.org/10.1140/epjst/e2010-01179-1"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.1140/epjst/e2010-01179-1</a></span>




</span></span>)</span>
 与Louvain方法相似，但使用了不同的优化目标。作者发现了社区发现与编码的联系，即最优的社区发现结果能够使得描述图上随机游走路径的编码长度最短。如下图所示。当未做社区划分时，对于图(a)中的随机游走，需要在图(b)中使用所有路径上顶点的编码进行描述，一共$314$bits；当把图划分成四个社区后，在图(c)中，为每个社区设定起始编码和中止编码，路径节点的编码长度可以缩小，这样整条游走路径的编码长度缩短为$243$bits；在图(d)中，若忽略社区内部的游走路径，则可以产生更短的的粗糙编码。</p>
<img src="https://raw.githubusercontent.com/yliuhz/blogs/master/content/posts/iShot_2023-06-20_10.36.17.png" />
<p>对于一个含有$n$个节点的图，可以将其划分为$1,2,\cdots,n$个社区，即一共有$n$种社区个数的选择（下图中为$1,2,\cdots,25$共25种选择）。在比较不同社区划分对编码长度的影响时，作者发现，描述社区的平均编码长度随着社区个数的增加而单调递增，描述节点的平均编码长度随着社区个数的增加而单调递减。将二者相加即为描述游走路径的平均编码长度。当产生最优的社区个数($4$)时，平均编码长度最短($3.09$bits)</p>
<img src="https://raw.githubusercontent.com/yliuhz/blogs/master/content/posts/iShot_2023-06-20_10.36.29.png" />
<p>具体来说，Infomap的优化目标是最小化如下的Map Equation。</p>
<p>$$L(M)=q_{\curvearrowright}H(Q)+\sum_{i=1}^mp_{\circlearrowright}^iH(P^i)$$</p>
<p>其中$H(Q),H(P^i)$分别描述节点编码的平均长度和描述社区$i$的编码平均长度。$q_{i\curvearrowright}$表示离开社区$i$的概率，$q_{\curvearrowright}=\sum_{i=1}^mq_{i\curvearrowright}$表示随机游走切换社区的概率。$p_{\alpha}$表示访问节点$\alpha$的概率，$p_{\circlearrowright}=\sum_{\alpha\in i}p_{\alpha}+q_{i\curvearrowright}$表示访问及离开社区$i$的概率之和。</p>
<p>它基于香农源编码定理：当使用$n$个编码描述一个随机变量$X$的$n$种状态时，若每个状态$i$出现的概率为$p_i$，则该编码的长度不能低于随机变量$X$自身的熵：$H(X)=-\sum_{i=1}^np_i\log(p_i)$。</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>GNN and MLP</title>
      <link>https://yliuhz.github.io/blogs/posts/gnn2mlp/</link>
      <pubDate>Thu, 08 Jun 2023 16:37:51 +0800</pubDate>
      
      <guid>https://yliuhz.github.io/blogs/posts/gnn2mlp/</guid>
      <description>最近发现一篇ICLR2023 spotlight的蒸馏GNN到MLP的论文 ( Citation: Tian,&amp;#32;Zhang &amp;amp; al.,&amp;#32;2023 Tian,&amp;#32; Y.,&amp;#32; Zhang,&amp;#32; C.,&amp;#32; Guo,&amp;#32; Z.,&amp;#32; Zhang,&amp;#32; X.&amp;#32;&amp;amp;&amp;#32;Chawla,&amp;#32; N. &amp;#32; (2023). &amp;#32;NOSMOG: Learning Noise-robust and Structure-aware MLPs on Graphs. https://doi.org/10.48550/arXiv.2208.10010 ) ，觉得很新鲜。向前追溯发现其是基于ICLR2022的GLNN ( Citation: Zhang,&amp;#32;Liu &amp;amp; al.,&amp;#32;2022 Zhang,&amp;#32; S.,&amp;#32; Liu,&amp;#32; Y.,&amp;#32; Sun,&amp;#32; Y.&amp;#32;&amp;amp;&amp;#32;Shah,&amp;#32; N. &amp;#32; (2022). &amp;#32;Graph-less Neural Networks: Teaching Old MLPs New Tricks via Distillation. https://doi.org/10.48550/arXiv.2110.08727 ) 做的，遂在这里整理一下相关内容和自己的理解。
Graph-less Neural Networks (GLNN) 作者 ( Citation: Zhang,&amp;#32;Liu &amp;amp; al.,&amp;#32;2022 Zhang,&amp;#32; S.,&amp;#32; Liu,&amp;#32; Y.,&amp;#32; Sun,&amp;#32; Y.</description>
      <content:encoded><![CDATA[<p>最近发现一篇ICLR2023 spotlight的蒸馏GNN到MLP的论文 




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#49r47o4e"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Yijun"><span itemprop="familyName">Tian</span></span>,&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Chuxu"><span itemprop="familyName">Zhang</span></span>
                  <em>&amp; al.</em>,&#32;<span itemprop="datePublished">2023</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Tian</span>,&#32;
    <meta itemprop="givenName" content="Yijun" />
    Y.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Zhang</span>,&#32;
    <meta itemprop="givenName" content="Chuxu" />
    C.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Guo</span>,&#32;
    <meta itemprop="givenName" content="Zhichun" />
    Z.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Zhang</span>,&#32;
    <meta itemprop="givenName" content="Xiangliang" />
    X.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Chawla</span>,&#32;
    <meta itemprop="givenName" content="Nitesh V." />
    N.</span>
  &#32;
    (<span itemprop="datePublished">2023</span>).
  &#32;<span itemprop="name">NOSMOG: Learning Noise-robust and Structure-aware MLPs on Graphs</span>.
  <a href="https://doi.org/10.48550/arXiv.2208.10010"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.2208.10010</a></span>




</span></span>)</span>
，觉得很新鲜。向前追溯发现其是基于ICLR2022的GLNN 




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#demqp61a"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Shichang"><span itemprop="familyName">Zhang</span></span>,&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Yozen"><span itemprop="familyName">Liu</span></span>
                  <em>&amp; al.</em>,&#32;<span itemprop="datePublished">2022</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Zhang</span>,&#32;
    <meta itemprop="givenName" content="Shichang" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Liu</span>,&#32;
    <meta itemprop="givenName" content="Yozen" />
    Y.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Sun</span>,&#32;
    <meta itemprop="givenName" content="Yizhou" />
    Y.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Shah</span>,&#32;
    <meta itemprop="givenName" content="Neil" />
    N.</span>
  &#32;
    (<span itemprop="datePublished">2022</span>).
  &#32;<span itemprop="name">Graph-less Neural Networks: Teaching Old MLPs New Tricks via Distillation</span>.
  <a href="https://doi.org/10.48550/arXiv.2110.08727"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.2110.08727</a></span>




</span></span>)</span>
做的，遂在这里整理一下相关内容和自己的理解。</p>
<h2 id="graph-less-neural-networks-glnn">Graph-less Neural Networks (GLNN)</h2>
<p>作者 




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#demqp61a"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Shichang"><span itemprop="familyName">Zhang</span></span>,&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Yozen"><span itemprop="familyName">Liu</span></span>
                  <em>&amp; al.</em>,&#32;<span itemprop="datePublished">2022</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Zhang</span>,&#32;
    <meta itemprop="givenName" content="Shichang" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Liu</span>,&#32;
    <meta itemprop="givenName" content="Yozen" />
    Y.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Sun</span>,&#32;
    <meta itemprop="givenName" content="Yizhou" />
    Y.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Shah</span>,&#32;
    <meta itemprop="givenName" content="Neil" />
    N.</span>
  &#32;
    (<span itemprop="datePublished">2022</span>).
  &#32;<span itemprop="name">Graph-less Neural Networks: Teaching Old MLPs New Tricks via Distillation</span>.
  <a href="https://doi.org/10.48550/arXiv.2110.08727"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.2110.08727</a></span>




</span></span>)</span>
 指出现实场景难以落地GNN的一大原因是GNN的推理速度很慢。假设图中平均的顶点度为$R$，那么对于一个$L$层GNN的网络，总共需要提取(fetch)$O(R^L)$次邻居和自己的节点特征。如下图所示。该指数量级的提取次数导致GNN的推理时间随层数增加而指数上升。
另一方面，多层感知机MLP由于不需要图结构作为输入，因此无需提取其他节点的特征，推理速度是线性的。</p>
<img src="https://raw.githubusercontent.com/yliuhz/blogs/master/content/posts/iShot_2023-06-08_16.43.02.png" />
<p>为了节省推理时间，直接使用MLP在图上训练也是不可行的，因为丢掉了图结构信息。为了达到MLP的推理时间同时尽量保留图的结构信息，作者提出了从GNN蒸馏知识到MLP的方法，并验证了其有效性。</p>
<h3 id="解决框架">解决框架</h3>
<p>GLNN的结构容易理解，先训练一个笨重的GNN模型作为教师模型，再使用该GNN的输出$\mathbf{z}_v$以及带标签节点本身的标签$\mathbf{y}_v$训练简单的MLP学生网络。在归纳式学习(inductive learning)场景中，
<strong>当新的节点到来时，不再考虑其与训练图结构的连边，而是直接输入到MLP中做推理。</strong>
如下图所示。</p>
<img src="https://raw.githubusercontent.com/yliuhz/blogs/master/content/posts/iShot_2023-06-08_16.48.33.png" />
<p>作者对于直推式和归纳式的详细描述：
<img src="https://raw.githubusercontent.com/yliuhz/blogs/master/content/posts/iShot_2023-06-08_17.19.08.png" />
<img src="https://raw.githubusercontent.com/yliuhz/blogs/master/content/posts/iShot_2023-06-08_17.19.13.png" />
可以看到测试时MLP和GLNN的学生网络是没有图结构输入的，只有测试顶点的特征向量。
同时，在测试教师网络GNN的归纳式推理时，只使用训练集图结构训练，而在测试时使用了包括测试顶点在内的整张图作为输入。这样对比是公平的。因为在使用GNN模型推理时我们会尽可能发挥模型的性能，为模型提供尽可能多的信息（<strong>见代码</strong> <a href="https://github.com/snap-research/graphless-neural-networks/blob/76da5d1b5d8258d5ea9ae7d4fa63f6a20a47c27c/train_and_eval.py#L731-L736">official code</a>）。</p>
<p>训练学生网络时使用的损失函数为</p>
<p>$$\mathcal{L}=\lambda\sum_{v\in\mathcal{V}^L}\mathcal{L}_{label}(\hat{\mathbf{y}}_v,\mathbf{y}_v)+(1-\lambda)\sum_{v\in\mathcal{V}}\mathcal{L}_{teacher}(\hat{\mathbf{y}}_v,\mathbf{z}_v)$$</p>
<p>其中$\mathcal{L}_{label}$为交叉熵损失，$\mathcal{L}_{teacher}$为KL散度损失，$\lambda\in[0,1]$是超参数，$\mathcal{V}^L$表示带标签的训练节点，$\mathcal{V}$表示所有训练节点。$\mathcal{L}_{teacher}$的含义是使学生网络输出的分布与教师网络的输出分布相近。</p>
<h3 id="实验">实验</h3>
<p>作者做了大量的实验，包括直推式(transductive)的推理、归纳式(inductive)的推理，与其他GNN加速方法做了比较，通过一个参量(min-cut loss)验证蒸馏的有效性，验证GLNN的表达能力(理论推导)，分析了GLNN失败的场景。参数实验（消融实验）中验证了特征中加噪声的影响，归纳式推理时不同训练测试划分的影响，以及使用其他教师网络模型的情况。在附录部分还加了在异配图（NON-HOMOPHILY）上的实验，并更加详细地分析了节点特征噪声对GLNN的影响。</p>
<p>作者指出虽然现实场景中大多是归纳式推理，但直推式推理的实验仍然是有意义的(附录A.5)。第一，大多数现有GNN文献使用的是直推式的推理，为了公平对比。第二，直推式推理相对简单，因为在训练时看到了测试节点的特征。只有直推式能够work才能接着考虑更有挑战性的归纳式推理。第三，因为半监督训练时使用的标签很少，如pubmed数据集只有每个类别20个共60个标签，作者希望尽可能使用更多无标签节点提升性能。在现实场景中，当有很多无标签节点需要推理时，同样可以把它们拿来训练，然后用另一组不同的带标签测试节点做评测。</p>
<p>在附录J中，作者详细讨论了使用噪声扰动节点特征的实验结果(如下图Left)。发现2点：</p>
<ol>
<li>当节点特征为纯高斯噪声($\alpha=1$)时，原始GNN仍然相对较好；</li>
<li>当节点特征为纯高斯噪声($\alpha=1$)时，蒸馏的GLNN比纯训练MLP好。</li>
</ol>
<img src="https://raw.githubusercontent.com/yliuhz/blogs/master/content/posts/iShot_2023-06-09_09.49.47.png" />
<p>觉得这两个结果特殊是因为作者在正文5.8简单分析了什么情况下GLNN会失效，通过互信息：</p>
<p>$$I(G;y_i)=I(X^{[i]},\mathcal{E}^{[i]};y_i)=I(\mathcal{E}^{[i]};y_i)+I(X^{[i]};y_i|\mathcal{E}^{[i]})$$</p>
<p>最小化$\mathcal{L}_{label}$相当于在最大化$I(G;y_i)$。在上式中，$I(\mathcal{E}^{[i]};y_i)$表示边与节点标签的互信息，<strong>这是MLP无法访问到的</strong>。因此MLP只能最大化第二项$I(X^{[i]};y_i|\mathcal{E}^{[i]})$。然而，当节点的标签与特征无关时，比如节点的标签表示节点的度或者节点是否构成一个三角形，此时MLP和GLNN的学生网络都无法学到单单从节点特征到标签的映射$f$。这样分析的话上面的第2条实验结果就有点奇怪。</p>
<p>作者在附录J首先分析了为什么GNN在随机节点特征数据上仍然表现良好：<strong>过拟合</strong>。假设有一个A,B,C,D共4个顶点构成的全连接图(clique)，以及只与D相连的顶点E。令A,B,C,D的节点特征为纯高斯噪声，且具有相同的标签c。现在使用B,C,D,E训练GNN，A用作归纳测试。假设使用1层GNN。由于B,C,D内部的连边过于稠密，导致聚合邻居后B,C,D的表征十分地接近，而E对D的影响则十分小。因此模型会过拟合地将B,C,D的特征映射到标签c。当使用A做测试时，同样的聚合操作导致A与B,C,D十分接近，因此会输出相同的标签c，从而导致分类正确（GNN归纳式推理时使用全部邻接矩阵作为输入）。总的来说，<strong>如果A与许多具有相同标签的训练邻居稠密连接，那么就可能训练出一个过拟合的分类器，直接将其映射到相同的标签。</strong></p>
<p>第二分析了为什么GLNN的学生网络好于MLP：<strong>测试集标签的不平衡</strong>。按照现有的训练/测试集划分，训练集的节点标签是均衡的，而测试集可能是不均衡的。结果是，MLP的预测也相对均衡，而GLNN可以从教师网络的soft labels中学习，因此GLNN的预测标签分布与真实的不平衡标签分布更加相似。如下图所示。</p>
<img src="https://raw.githubusercontent.com/yliuhz/blogs/master/content/posts/iShot_2023-06-08_20.54.42.png" />
<h2 id="noise-robust-structure-aware-mlps-on-graphs-nosmog">NOise-robust Structure-aware MLPs On Graphs (NOSMOG)</h2>
<p>解决的问题和框架基本和GLNN相同，作者 




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#49r47o4e"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Yijun"><span itemprop="familyName">Tian</span></span>,&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Chuxu"><span itemprop="familyName">Zhang</span></span>
                  <em>&amp; al.</em>,&#32;<span itemprop="datePublished">2023</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Tian</span>,&#32;
    <meta itemprop="givenName" content="Yijun" />
    Y.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Zhang</span>,&#32;
    <meta itemprop="givenName" content="Chuxu" />
    C.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Guo</span>,&#32;
    <meta itemprop="givenName" content="Zhichun" />
    Z.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Zhang</span>,&#32;
    <meta itemprop="givenName" content="Xiangliang" />
    X.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Chawla</span>,&#32;
    <meta itemprop="givenName" content="Nitesh V." />
    N.</span>
  &#32;
    (<span itemprop="datePublished">2023</span>).
  &#32;<span itemprop="name">NOSMOG: Learning Noise-robust and Structure-aware MLPs on Graphs</span>.
  <a href="https://doi.org/10.48550/arXiv.2208.10010"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.2208.10010</a></span>




</span></span>)</span>
针对GLNN存在的不足进行优化。两大卖点是标题中的对噪声的鲁棒和对图结构的感知。使用对抗学习解决噪声的干扰，效果如下图：</p>
<img src="https://raw.githubusercontent.com/yliuhz/blogs/master/content/posts/iShot_2023-06-09_14.52.45.png" alt="image" width=50%/>
<h2 id="扩展">扩展</h2>
<ul>
<li>GLNN 文中一个重要的结论是，对于现实中的属性图数据集，使用与GNN相同的参数量，<strong>存在一组MLP的参数，由节点的特征向量映射到其类别标签而取得与GNN相近的准确率</strong>，只是单单使用MLP以及标准的随机梯度下降难以学习到这样的参数 (5.3节、5.6节)。这表明节点的特征向量本身具有足够多的信息。这启发了后续KDD2022的GraphMAE 




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#6imlcek9"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Zhenyu"><span itemprop="familyName">Hou</span></span>,&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Xiao"><span itemprop="familyName">Liu</span></span>
                  <em>&amp; al.</em>,&#32;<span itemprop="datePublished">2022</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Hou</span>,&#32;
    <meta itemprop="givenName" content="Zhenyu" />
    Z.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Liu</span>,&#32;
    <meta itemprop="givenName" content="Xiao" />
    X.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Cen</span>,&#32;
    <meta itemprop="givenName" content="Yukuo" />
    Y.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Dong</span>,&#32;
    <meta itemprop="givenName" content="Yuxiao" />
    Y.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Yang</span>,&#32;
    <meta itemprop="givenName" content="Hongxia" />
    H.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Wang</span>,&#32;
    <meta itemprop="givenName" content="Chunjie" />
    C.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Tang</span>,&#32;
    <meta itemprop="givenName" content="Jie" />
    J.</span>
  &#32;
    (<span itemprop="datePublished">2022</span>).
  &#32;<span itemprop="name">GraphMAE: Self-Supervised Masked Graph Autoencoders</span>.
  <a href="https://doi.org/10.48550/arXiv.2205.10803"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.2205.10803</a></span>




</span></span>)</span>
 构建重构特征的图自编码器。</li>
</ul>
<img src="https://raw.githubusercontent.com/yliuhz/blogs/master/content/posts/iShot_2023-06-13_15.17.19.png" width=80% class="center"/>
<ul>
<li>ICLR2023 还有一篇联系GNN与MLP的文章 




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#byadi6ga"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Chenxiao"><span itemprop="familyName">Yang</span></span>,&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Qitian"><span itemprop="familyName">Wu</span></span>
                  <em>&amp; al.</em>,&#32;<span itemprop="datePublished">2023</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Yang</span>,&#32;
    <meta itemprop="givenName" content="Chenxiao" />
    C.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Wu</span>,&#32;
    <meta itemprop="givenName" content="Qitian" />
    Q.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Wang</span>,&#32;
    <meta itemprop="givenName" content="Jiahua" />
    J.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Yan</span>,&#32;
    <meta itemprop="givenName" content="Junchi" />
    J.</span>
  &#32;
    (<span itemprop="datePublished">2023</span>).
  &#32;<span itemprop="name">Graph Neural Networks are Inherently Good Generalizers: Insights by Bridging GNNs and MLPs</span>.
  <a href="https://doi.org/10.48550/arXiv.2212.09034"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.2212.09034</a></span>




</span></span>)</span>
。与GLNN不同，PMLP 




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#byadi6ga"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Chenxiao"><span itemprop="familyName">Yang</span></span>,&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Qitian"><span itemprop="familyName">Wu</span></span>
                  <em>&amp; al.</em>,&#32;<span itemprop="datePublished">2023</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Yang</span>,&#32;
    <meta itemprop="givenName" content="Chenxiao" />
    C.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Wu</span>,&#32;
    <meta itemprop="givenName" content="Qitian" />
    Q.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Wang</span>,&#32;
    <meta itemprop="givenName" content="Jiahua" />
    J.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Yan</span>,&#32;
    <meta itemprop="givenName" content="Junchi" />
    J.</span>
  &#32;
    (<span itemprop="datePublished">2023</span>).
  &#32;<span itemprop="name">Graph Neural Networks are Inherently Good Generalizers: Insights by Bridging GNNs and MLPs</span>.
  <a href="https://doi.org/10.48550/arXiv.2212.09034"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.2212.09034</a></span>




</span></span>)</span>
 在训练时采用MLP架构，而在测试时重新添加信息传递(message passing, MP)操作，同样取得了与GNN相近的准确率。测试时MP添加的位置和次数可以自主设定。作者在与不同的原始GNN架构对比时使用了不同的PMLP测试架构。如下图所示 (来源于作者的报告: <a href="https://www.bilibili.com/video/BV1uh4y1G794/?spm_id_from=333.999.0.0&amp;vd_source=5bc35454eb5381b6bccf1051510ae36a">bilibili</a>)。</li>
</ul>
<img src="https://raw.githubusercontent.com/yliuhz/blogs/master/content/posts/iShot_2023-06-13_11.38.14.png" width=80% class="center"/>
<img src="https://raw.githubusercontent.com/yliuhz/blogs/master/content/posts/iShot_2023-06-13_11.38.26.png" width=80% class="center"/>
<ul>
<li>还有研究者整理了近期GNN&amp;MLP的论文在<a href="https://github.com/wutaiqiang/awesome-GNN2MLP-distillation">Github</a>。</li>
</ul>
<h2 id="references">References</h2>

  

  










<section class="hugo-cite-bibliography">
  <dl>
    

      <div id="49r47o4e">
        <dt>
          Tian,&#32;
          Zhang,&#32;
          Guo,&#32;
          Zhang&#32;&amp;&#32;Chawla

          
          (2023)</dt>

        <dd>
          










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Tian</span>,&#32;
    <meta itemprop="givenName" content="Yijun" />
    Y.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Zhang</span>,&#32;
    <meta itemprop="givenName" content="Chuxu" />
    C.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Guo</span>,&#32;
    <meta itemprop="givenName" content="Zhichun" />
    Z.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Zhang</span>,&#32;
    <meta itemprop="givenName" content="Xiangliang" />
    X.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Chawla</span>,&#32;
    <meta itemprop="givenName" content="Nitesh V." />
    N.</span>
  &#32;
    (<span itemprop="datePublished">2023</span>).
  &#32;<span itemprop="name">NOSMOG: Learning Noise-robust and Structure-aware MLPs on Graphs</span>.
  <a href="https://doi.org/10.48550/arXiv.2208.10010"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.2208.10010</a></span>




</dd>

      </div>

      <div id="6imlcek9">
        <dt>
          Hou,&#32;
          Liu,&#32;
          Cen,&#32;
          Dong,&#32;
          Yang,&#32;
          Wang&#32;&amp;&#32;Tang

          
          (2022)</dt>

        <dd>
          










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Hou</span>,&#32;
    <meta itemprop="givenName" content="Zhenyu" />
    Z.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Liu</span>,&#32;
    <meta itemprop="givenName" content="Xiao" />
    X.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Cen</span>,&#32;
    <meta itemprop="givenName" content="Yukuo" />
    Y.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Dong</span>,&#32;
    <meta itemprop="givenName" content="Yuxiao" />
    Y.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Yang</span>,&#32;
    <meta itemprop="givenName" content="Hongxia" />
    H.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Wang</span>,&#32;
    <meta itemprop="givenName" content="Chunjie" />
    C.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Tang</span>,&#32;
    <meta itemprop="givenName" content="Jie" />
    J.</span>
  &#32;
    (<span itemprop="datePublished">2022</span>).
  &#32;<span itemprop="name">GraphMAE: Self-Supervised Masked Graph Autoencoders</span>.
  <a href="https://doi.org/10.48550/arXiv.2205.10803"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.2205.10803</a></span>




</dd>

      </div>

      <div id="byadi6ga">
        <dt>
          Yang,&#32;
          Wu,&#32;
          Wang&#32;&amp;&#32;Yan

          
          (2023)</dt>

        <dd>
          










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Yang</span>,&#32;
    <meta itemprop="givenName" content="Chenxiao" />
    C.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Wu</span>,&#32;
    <meta itemprop="givenName" content="Qitian" />
    Q.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Wang</span>,&#32;
    <meta itemprop="givenName" content="Jiahua" />
    J.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Yan</span>,&#32;
    <meta itemprop="givenName" content="Junchi" />
    J.</span>
  &#32;
    (<span itemprop="datePublished">2023</span>).
  &#32;<span itemprop="name">Graph Neural Networks are Inherently Good Generalizers: Insights by Bridging GNNs and MLPs</span>.
  <a href="https://doi.org/10.48550/arXiv.2212.09034"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.2212.09034</a></span>




</dd>

      </div>

      <div id="demqp61a">
        <dt>
          Zhang,&#32;
          Liu,&#32;
          Sun&#32;&amp;&#32;Shah

          
          (2022)</dt>

        <dd>
          










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Zhang</span>,&#32;
    <meta itemprop="givenName" content="Shichang" />
    S.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Liu</span>,&#32;
    <meta itemprop="givenName" content="Yozen" />
    Y.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Sun</span>,&#32;
    <meta itemprop="givenName" content="Yizhou" />
    Y.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Shah</span>,&#32;
    <meta itemprop="givenName" content="Neil" />
    N.</span>
  &#32;
    (<span itemprop="datePublished">2022</span>).
  &#32;<span itemprop="name">Graph-less Neural Networks: Teaching Old MLPs New Tricks via Distillation</span>.
  <a href="https://doi.org/10.48550/arXiv.2110.08727"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://doi.org/10.48550/arXiv.2110.08727</a></span>




</dd>

      </div>
  </dl>
</section>



]]></content:encoded>
    </item>
    
    <item>
      <title>Diffusion Models</title>
      <link>https://yliuhz.github.io/blogs/posts/diffusion/</link>
      <pubDate>Wed, 24 May 2023 10:45:03 +0800</pubDate>
      
      <guid>https://yliuhz.github.io/blogs/posts/diffusion/</guid>
      <description>So why diffusion models perform well?
When \(a \ne 0\), there are two solutions to \(ax^2 + bx + c = 0\) and they are \[x = {-b \pm \sqrt{b^2-4ac} \over 2a}.\] $a^2$
$$b^2$$</description>
      <content:encoded><![CDATA[<p><strong>So why diffusion models perform well?</strong></p>
<div>
  When \(a \ne 0\), there are two solutions to \(ax^2 + bx + c = 0\) and they are
  \[x = {-b \pm \sqrt{b^2-4ac} \over 2a}.\]
</div>
<p>$a^2$</p>
<p>$$b^2$$</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>VAE</title>
      <link>https://yliuhz.github.io/blogs/posts/vae/</link>
      <pubDate>Tue, 23 May 2023 20:42:27 +0800</pubDate>
      
      <guid>https://yliuhz.github.io/blogs/posts/vae/</guid>
      <description>Variational Autoencoders 原博主为Lilian Weng
与简单的自编码器不同，变分自编码器的表征$\mathbf{z}$是一个分布。 给定一个数据集$\mathbf{X}=\{\mathbf{x}_i\}_{i=1}^N$，变分自编码器的观点是$\mathbf{x}$由一个隐变量$\mathbf{z}$产生，而$\mathbf{z}$则遵循一个先验分布，通常取正态分布。 因此，变分自编码器可以由3个概率分布刻画：
$p(\mathbf{z})$: 先验分布 $p(\mathbf{x}|\mathbf{z})$: 解码器 $p(\mathbf{z}|\mathbf{x})$: 后验分布，编码器 其中后验分布很难直接计算，因此自编码器从一个未训练过的编码器，即对后验分布的估计$q(\mathbf{z}|\mathbf{x})$开始，通过优化目标函数不断逼近$q(\mathbf{z}|\mathbf{x})$和$p(\mathbf{z}|\mathbf{x})$的距离。
这里使用KL散度衡量两个分布的距离，即$D_{KL}(q(\mathbf{z}|\mathbf{x})||p(\mathbf{z}|\mathbf{x}))$。注意KL散度不具有对称性，原博主Lilian Weng甚至指出了为什么不使用$D_{KL}(p(\mathbf{z}|\mathbf{x})||q(\mathbf{z}|\mathbf{x}))$。
具体来说，前向KL散度$D_{KL}(p||q)=\mathbb{E}_{\mathbf{z}\sim p(\mathbf{z})}\log \frac{p(\mathbf{z})}{q(\mathbf{z})}=\int p(\mathbf{z})\log \frac{p(\mathbf{z})}{q(\mathbf{z})}d\mathbf{z}$中，p&amp;gt;0的位置要求q必须同时&amp;gt;0(因为$\lim_{q\to 0}p\log \frac{p}{q}\to \infty$)。因此优化前向KL散度会导致q覆盖了每个p分布概率不为0的点。反过来，我们这里使用的反向KL散度$D_{KL}(q||p)=\mathbb{E}_{\mathbf{z}\sim q(\mathbf{z})}\log \frac{q(\mathbf{z})}{p(\mathbf{z})}=\int q(\mathbf{z})\log \frac{q(\mathbf{z})}{p(\mathbf{z})}d\mathbf{z}$，在p=0时保证了q必须=0。
前向KL散度：p&amp;gt;0时q&amp;gt;0，可能导致q平铺在p&amp;gt;0的区域 反向KL散度（使用的）：p=0时q=0，可能导致q被挤压在p的一个峰上 在推导KL散度的表达式时就可以得到变分自编码器的损失函数ELBO。
(图源Lilian Weng的博客：https://lilianweng.github.io/posts/2018-08-12-vae/)
我们想同时极大化观测数据点$\mathbf{x}$的似然，以及真假编码器的分布差距，即最大化 $$\mathbb{E}_{\mathbf{z}\sim q(\mathbf{z}|\mathbf{x})}\log p(\mathbf{x}|\mathbf{z})-D_{KL}(q(\mathbf{z}|\mathbf{x})||p(\mathbf{z}))$$ 左边的是重构误差取反，右边的在先验分布为正态分布时可以显式展开。
在计算重构误差时用到了重参数技巧（reparameterization trick），即把从一个带参数的编码器采样$\mathbf{z}$，转化为从一个确定的分布（如标准正态）采样一个值，再通过将采样的值与编码器的输出（均值和方差）加减乘除得到$\mathbf{z}$。这样梯度就和采样独立开来，可以反向传播了。</description>
      <content:encoded><![CDATA[<h2 id="variational-autoencoders">Variational Autoencoders</h2>
<p>原博主为<a href="https://lilianweng.github.io/posts/2018-08-12-vae/">Lilian Weng</a></p>
<p>与简单的自编码器不同，变分自编码器的表征$\mathbf{z}$是一个分布。
给定一个数据集$\mathbf{X}=\{\mathbf{x}_i\}_{i=1}^N$，变分自编码器的观点是$\mathbf{x}$由一个隐变量$\mathbf{z}$产生，而$\mathbf{z}$则遵循一个先验分布，通常取正态分布。
因此，变分自编码器可以由3个概率分布刻画：</p>
<ul>
<li>$p(\mathbf{z})$: 先验分布</li>
<li>$p(\mathbf{x}|\mathbf{z})$: 解码器</li>
<li>$p(\mathbf{z}|\mathbf{x})$: 后验分布，编码器</li>
</ul>
<p>其中后验分布很难直接计算，因此自编码器从一个未训练过的编码器，即对后验分布的估计$q(\mathbf{z}|\mathbf{x})$开始，通过优化目标函数不断逼近$q(\mathbf{z}|\mathbf{x})$和$p(\mathbf{z}|\mathbf{x})$的距离。</p>
<p>这里使用KL散度衡量两个分布的距离，即$D_{KL}(q(\mathbf{z}|\mathbf{x})||p(\mathbf{z}|\mathbf{x}))$。注意KL散度不具有对称性，原博主<a href="https://lilianweng.github.io/posts/2018-08-12-vae/">Lilian Weng</a>甚至指出了为什么不使用$D_{KL}(p(\mathbf{z}|\mathbf{x})||q(\mathbf{z}|\mathbf{x}))$。</p>
<p>具体来说，前向KL散度$D_{KL}(p||q)=\mathbb{E}_{\mathbf{z}\sim p(\mathbf{z})}\log \frac{p(\mathbf{z})}{q(\mathbf{z})}=\int p(\mathbf{z})\log \frac{p(\mathbf{z})}{q(\mathbf{z})}d\mathbf{z}$中，p&gt;0的位置要求q必须同时&gt;0(因为$\lim_{q\to 0}p\log \frac{p}{q}\to \infty$)。因此优化前向KL散度会导致q覆盖了每个p分布概率不为0的点。反过来，我们这里使用的反向KL散度$D_{KL}(q||p)=\mathbb{E}_{\mathbf{z}\sim q(\mathbf{z})}\log \frac{q(\mathbf{z})}{p(\mathbf{z})}=\int q(\mathbf{z})\log \frac{q(\mathbf{z})}{p(\mathbf{z})}d\mathbf{z}$，在p=0时保证了q必须=0。</p>
<ul>
<li>前向KL散度：p&gt;0时q&gt;0，可能导致q平铺在p&gt;0的区域</li>
<li>反向KL散度（使用的）：p=0时q=0，可能导致q被挤压在p的一个峰上</li>
</ul>
<img src="https://raw.githubusercontent.com/yliuhz/blogs/master/content/posts/forward_vs_reversed_KL.png"/>
<p>在推导KL散度的表达式时就可以得到变分自编码器的损失函数ELBO。</p>
<img src="https://raw.githubusercontent.com/yliuhz/blogs/master/content/posts/iShot_2023-05-23_20.26.52.png" width=80%/>
<p align="center" style="color:grey">(图源Lilian Weng的博客：https://lilianweng.github.io/posts/2018-08-12-vae/)</p>
<p>我们想同时极大化观测数据点$\mathbf{x}$的似然，以及真假编码器的分布差距，即最大化
$$\mathbb{E}_{\mathbf{z}\sim q(\mathbf{z}|\mathbf{x})}\log p(\mathbf{x}|\mathbf{z})-D_{KL}(q(\mathbf{z}|\mathbf{x})||p(\mathbf{z}))$$
左边的是重构误差取反，右边的在先验分布为正态分布时可以显式展开。</p>
<p>在计算重构误差时用到了重参数技巧（reparameterization trick），即把从一个带参数的编码器采样$\mathbf{z}$，转化为从一个确定的分布（如标准正态）采样一个值，再通过将采样的值与编码器的输出（均值和方差）加减乘除得到$\mathbf{z}$。这样梯度就和采样独立开来，可以反向传播了。</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>FlashAttention</title>
      <link>https://yliuhz.github.io/blogs/posts/flashattention/</link>
      <pubDate>Thu, 18 May 2023 18:59:54 +0800</pubDate>
      
      <guid>https://yliuhz.github.io/blogs/posts/flashattention/</guid>
      <description>FlashAttention论文发表于Neurips2022，第一单位是斯坦福大学。
作者提出了一种使用更小代价计算self-attention的方法，并从理论上保证flash-attention给出的是精确的attention值，与现有的近似attention不同。作者指出现有方法专注于减少FLOPs，而本文专注于减少IO。
输入：$\mathbf{Q},\mathbf{K},\mathbf{V}\in\mathbb{R}^{N\times d}$
输出：$\mathbf{O}\in\mathbb{R}^{N\times d}$
标准self-attention：
$\mathbf{S}=\mathbf{Q}\mathbf{K}^T\in\mathbb{R}^{N\times N}$
$\mathbf{P}=\exp(\mathbf{S})$
$\mathbf{O}=\mathbf{PV}/l(S)$，$l$始终表示向量元素求和或矩阵按行求和。
Flash-attention的思路：分块在高速on-chip显存上增量式计算，避免平方空间的$\mathbf{S}$。
首先推导增量式的softmax函数：
对一个向量$\mathbf{x}$计算softmax：$\sigma(\mathbf{x})=\exp(\mathbf{x})/{\sum_i {\exp(\mathbf{x}_i)}}$
对两个向量的拼接$[\mathbf{x},\mathbf{y}]$计算softmax：$\sigma([\mathbf{x},\mathbf{y}])=[\exp(\mathbf{x}),\exp(\mathbf{y})]/(\sum_i\exp(\mathbf{x}_i)+\sum_j\exp(\mathbf{y}_j))$
设$l(\mathbf{x})=\sum_i\exp(\mathbf{x}_i)$，则$\sigma([\mathbf{x},\mathbf{y}])=[\exp(\mathbf{x}),\exp(\mathbf{y})]/(l(\mathbf{x})+l(\mathbf{y}))$
将$\mathbf{Q,O},l$分成$T_r$块，将$\mathbf{K,V}$分成$T_c$块，进行二重循环。
1 2 3 4 for j in 1...T_c: 取出K_j和V_j for i in 1...T_r: 取出Q_i,O_i和l_i 计算当前块内的self-attention，即：
$\mathbf{S}_{ij}=\mathbf{Q}_i\mathbf{K}_j^T$
$\mathbf{P}_{ij}=\exp(\mathbf{S}_{ij})$
$l_{ij}=\text{rowsum}(\mathbf{P}_{ij})$
$\mathbf{O}_i&amp;rsquo;=\mathbf{P}_{ij}\mathbf{V}_j$
然后需要对上一轮的$\mathbf{O_i}$和$l_i$进行更新，以d=1为例。
$l_i^{new}=l_i+l_{ij}$比较直接
两个红色的矩阵相乘得到当前的$\mathbf{O}_{ij}$。我们知道上一轮softmax使用的$l_i$只是当前i行的前部分之和，因此这里要乘以旧分母除以新分母，同时由于绿色$\mathbf{O}_i$由i行j列的内积得来，还需要加上$\mathbf{O}_{ij}$，这样得到$\mathbf{O}_i$的增量式更新：
$\mathbf{O}_i=\mathbf{O}_i*l_i/l_i^{new} + \mathbf{O}_{ij}$
论文中的Algorithm1由于考虑了算术稳定性防止\exp得到过大的值，在softmax前减去了最大值m，因此看起来更复杂。
发散QA Q1. Algorithm 1中的i、j循环可以交换吗？github
A1. 如下可以，结果仍然保证Flash-Attention得到的是精确的$\mathbf{O}$。但显然增加了$\mathbf{K}_j$和$\mathbf{V}_j$的IO次数。
1 2 3 4 5 6 7 8 for i in 1...T_r: for j in 1...T_c: 取出K_j和V_j 取出Q_i,O_i和l_i ... 更新O_i和l_i 如下不可以。</description>
      <content:encoded><![CDATA[<p><strong>FlashAttention</strong>论文发表于Neurips2022，第一单位是斯坦福大学。</p>
<p>作者提出了一种使用更小代价计算self-attention的方法，并从理论上保证flash-attention给出的是精确的attention值，与现有的近似attention不同。作者指出现有方法专注于减少FLOPs，而本文专注于减少IO。</p>
<p><strong>输入</strong>：$\mathbf{Q},\mathbf{K},\mathbf{V}\in\mathbb{R}^{N\times d}$</p>
<p><strong>输出</strong>：$\mathbf{O}\in\mathbb{R}^{N\times d}$</p>
<p>标准self-attention：</p>
<p>$\mathbf{S}=\mathbf{Q}\mathbf{K}^T\in\mathbb{R}^{N\times N}$</p>
<p>$\mathbf{P}=\exp(\mathbf{S})$</p>
<p>$\mathbf{O}=\mathbf{PV}/l(S)$，$l$始终表示向量元素求和或矩阵按行求和。</p>
<p>Flash-attention的思路：分块在高速on-chip显存上<strong>增量式</strong>计算，避免平方空间的$\mathbf{S}$。</p>
<p>首先推导增量式的softmax函数：</p>
<p>对一个向量$\mathbf{x}$计算softmax：$\sigma(\mathbf{x})=\exp(\mathbf{x})/{\sum_i {\exp(\mathbf{x}_i)}}$</p>
<p>对两个向量的拼接$[\mathbf{x},\mathbf{y}]$计算softmax：$\sigma([\mathbf{x},\mathbf{y}])=[\exp(\mathbf{x}),\exp(\mathbf{y})]/(\sum_i\exp(\mathbf{x}_i)+\sum_j\exp(\mathbf{y}_j))$</p>
<p>设$l(\mathbf{x})=\sum_i\exp(\mathbf{x}_i)$，则$\sigma([\mathbf{x},\mathbf{y}])=[\exp(\mathbf{x}),\exp(\mathbf{y})]/(l(\mathbf{x})+l(\mathbf{y}))$</p>
<p>将$\mathbf{Q,O},l$分成$T_r$块，将$\mathbf{K,V}$分成$T_c$块，进行二重循环。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt" id="hl-0-1"><a class="lnlinks" href="#hl-0-1">1</a>
</span><span class="lnt" id="hl-0-2"><a class="lnlinks" href="#hl-0-2">2</a>
</span><span class="lnt" id="hl-0-3"><a class="lnlinks" href="#hl-0-3">3</a>
</span><span class="lnt" id="hl-0-4"><a class="lnlinks" href="#hl-0-4">4</a>
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="mf">1.</span><span class="o">..</span><span class="n">T_c</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">  <span class="n">取出K_j和V_j</span>
</span></span><span class="line"><span class="cl">  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="mf">1.</span><span class="o">..</span><span class="n">T_r</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">取出Q_i</span><span class="p">,</span><span class="n">O_i和l_i</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>计算当前块内的self-attention，即：</p>
<p>$\mathbf{S}_{ij}=\mathbf{Q}_i\mathbf{K}_j^T$</p>
<p>$\mathbf{P}_{ij}=\exp(\mathbf{S}_{ij})$</p>
<p>$l_{ij}=\text{rowsum}(\mathbf{P}_{ij})$</p>
<p>$\mathbf{O}_i&rsquo;=\mathbf{P}_{ij}\mathbf{V}_j$</p>
<p>然后需要对上一轮的$\mathbf{O_i}$和$l_i$进行更新，以d=1为例。</p>
<!-- ![image](https://raw.githubusercontent.com/yliuhz/blogs/master/content/posts/image-20230518194619599.png) -->
<img src="https://raw.githubusercontent.com/yliuhz/blogs/master/content/posts/image-20230518194619599.png" alt="image" width=50%/>
<p>$l_i^{new}=l_i+l_{ij}$比较直接</p>
<p>两个红色的矩阵相乘得到当前的$\mathbf{O}_{ij}$。我们知道上一轮softmax使用的$l_i$只是当前i行的前部分之和，因此这里要乘以旧分母除以新分母，同时由于绿色$\mathbf{O}_i$由i行j列的内积得来，还需要加上$\mathbf{O}_{ij}$，这样得到$\mathbf{O}_i$的增量式更新：</p>
<p>$\mathbf{O}_i=\mathbf{O}_i*l_i/l_i^{new} + \mathbf{O}_{ij}$</p>
<p>论文中的Algorithm1由于考虑了算术稳定性防止\exp得到过大的值，在softmax前减去了最大值m，因此看起来更复杂。</p>
<p>
  <img loading="lazy" src="https://raw.githubusercontent.com/yliuhz/blogs/master/content/posts/iShot_2023-05-19_09.53.57.png" alt="Algorithm 1"  /></p>
<h3 id="发散qa">发散QA</h3>
<p><strong>Q1</strong>. Algorithm 1中的i、j循环可以交换吗？<a href="https://github.com/yliuhz/awesome-papers/tree/main/FlashAttention">github</a></p>
<p><strong>A1</strong>. 如下可以，结果仍然保证Flash-Attention得到的是精确的$\mathbf{O}$。但显然增加了$\mathbf{K}_j$和$\mathbf{V}_j$的IO次数。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt" id="hl-1-1"><a class="lnlinks" href="#hl-1-1">1</a>
</span><span class="lnt" id="hl-1-2"><a class="lnlinks" href="#hl-1-2">2</a>
</span><span class="lnt" id="hl-1-3"><a class="lnlinks" href="#hl-1-3">3</a>
</span><span class="lnt" id="hl-1-4"><a class="lnlinks" href="#hl-1-4">4</a>
</span><span class="lnt" id="hl-1-5"><a class="lnlinks" href="#hl-1-5">5</a>
</span><span class="lnt" id="hl-1-6"><a class="lnlinks" href="#hl-1-6">6</a>
</span><span class="lnt" id="hl-1-7"><a class="lnlinks" href="#hl-1-7">7</a>
</span><span class="lnt" id="hl-1-8"><a class="lnlinks" href="#hl-1-8">8</a>
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="mf">1.</span><span class="o">..</span><span class="n">T_r</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">  <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="mf">1.</span><span class="o">..</span><span class="n">T_c</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">取出K_j和V_j</span>
</span></span><span class="line"><span class="cl">    <span class="n">取出Q_i</span><span class="p">,</span><span class="n">O_i和l_i</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="o">...</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">更新O_i和l_i</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>如下不可以。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt" id="hl-2-1"><a class="lnlinks" href="#hl-2-1">1</a>
</span><span class="lnt" id="hl-2-2"><a class="lnlinks" href="#hl-2-2">2</a>
</span><span class="lnt" id="hl-2-3"><a class="lnlinks" href="#hl-2-3">3</a>
</span><span class="lnt" id="hl-2-4"><a class="lnlinks" href="#hl-2-4">4</a>
</span><span class="lnt" id="hl-2-5"><a class="lnlinks" href="#hl-2-5">5</a>
</span><span class="lnt" id="hl-2-6"><a class="lnlinks" href="#hl-2-6">6</a>
</span><span class="lnt" id="hl-2-7"><a class="lnlinks" href="#hl-2-7">7</a>
</span><span class="lnt" id="hl-2-8"><a class="lnlinks" href="#hl-2-8">8</a>
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="mf">1.</span><span class="o">..</span><span class="n">T_r</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">  <span class="n">取出Q_i</span><span class="p">,</span><span class="n">O_i和l_i</span>
</span></span><span class="line"><span class="cl">  <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="mf">1.</span><span class="o">..</span><span class="n">T_c</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">取出K_j和V_j</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="o">...</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">  <span class="n">更新O_i和l_i</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><strong>Q2</strong>. $\mathbf{O}_i$的更新表达式怎么得来的？</p>
<p><strong>A2</strong>. $\mathbf{O}_i=\mathbf{O}_i*l_i/l_i^{new} + \mathbf{O}_{ij}$。$\mathbf{O}_i$由$\mathbf{S}$的第i行的softmax和$\mathbf{V}$的第j列的内积得来。然而在这里分块计算时，softmax的分母，即对行的求和值$l$，是在不断更新的。只有到$\mathbf{S}$的i行最后一列时才得到正确的l，因此有这样的增量更新表达式。</p>
<p>同时，不按当前的算式更新，每次只累加softmax的分母，直到最后一列才除以$l$，肯定也是可以的。</p>
<h3 id="references">References</h3>
<p>[1] 我的flash-attention实现：<a href="https://github.com/yliuhz/awesome-papers/tree/main/FlashAttention">awesome-papers/FlashAttention at main · yliuhz/awesome-papers (github.com)</a></p>
<p>[2] Flash Attention论文地址：<a href="https://doi.org/10.48550/arXiv.2205.14135">https://doi.org/10.48550/arXiv.2205.14135</a></p>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
