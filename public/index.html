<!doctype html><html lang=en dir=auto><head><meta name=generator content="Hugo 0.111.3"><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>LIU Yue's blogs</title><meta name=description content><meta name=author content="Yue"><link rel=canonical href=https://yliuhz.github.io/blogs/><link crossorigin=anonymous href=/blogs/assets/css/stylesheet.dc9bb5ce5660fc78ad32757018b41c1e0e7005f422801daf510da9bc9fdb0543.css integrity="sha256-3Ju1zlZg/HitMnVwGLQcHg5wBfQigB2vUQ2pvJ/bBUM=" rel="preload stylesheet" as=style><link rel=icon href=https://yliuhz.github.io/blogs/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://yliuhz.github.io/blogs/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://yliuhz.github.io/blogs/favicon-32x32.png><link rel=apple-touch-icon href=https://yliuhz.github.io/blogs/apple-touch-icon.png><link rel=mask-icon href=https://yliuhz.github.io/blogs/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://yliuhz.github.io/blogs/index.xml><link rel=alternate type=application/json href=https://yliuhz.github.io/blogs/index.json><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://yliuhz.github.io/blogs/css/extended/syntax.min.a2148732277aa7e9d7ccd409b4ecdc9f209783063d8fd3514ac8efd1d2647cf3.css integrity="sha256-ohSHMid6p+nXzNQJtOzcnyCXgwY9j9NRSsjv0dJkfPM="><meta property="og:title" content="LIU Yue's blogs"><meta property="og:description" content><meta property="og:type" content="website"><meta property="og:url" content="https://yliuhz.github.io/blogs/"><meta property="og:image" content="https://yliuhz.github.io/blogs/papermod-cover.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://yliuhz.github.io/blogs/papermod-cover.png"><meta name=twitter:title content="LIU Yue's blogs"><meta name=twitter:description content><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","name":"LIU Yue's blogs","url":"https://yliuhz.github.io/blogs","description":"","thumbnailUrl":"https://yliuhz.github.io/blogs/favicon.ico","sameAs":["https://github.com/yliuhz/","https://yliuhz.github.io","yliuhz@outlook.com"]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://yliuhz.github.io/blogs accesskey=h title="LIU Yue's blogs (Alt + H)">LIU Yue's blogs</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://yliuhz.github.io/blogs/archives title=Archive><span>Archive</span></a></li><li><a href=https://yliuhz.github.io/blogs/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://yliuhz.github.io/blogs/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class="first-entry home-info"><header class=entry-header><h1>LIU Yue&rsquo;s blogs</h1></header><div class=entry-content>Welcome to my personal blog. Any discussions are welcome. Reach me by <a href=mailto:yliuhz@outlook.com>yliuhz@outlook.com</a>.<br>欢迎来到我的个人博客！欢迎讨论！</div><footer class=entry-footer><div class=social-icons><a href=https://github.com/yliuhz/ target=_blank rel="noopener noreferrer me" title=Github><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a><a href=https://yliuhz.github.io target=_blank rel="noopener noreferrer me" title=Cv><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M4 4v16a2 2 0 002 2h12a2 2 0 002-2V8.342a2 2 0 00-.602-1.43l-4.44-4.342A2 2 0 0013.56 2H6A2 2 0 004 4z"/><path d="M9 13h6"/><path d="M9 17h3"/><path d="M14 2v4a2 2 0 002 2h4"/></svg></a><a href=yliuhz@outlook.com target=_blank rel="noopener noreferrer me" title=Email><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 21" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M4 4h16c1.1.0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1.0-2-.9-2-2V6c0-1.1.9-2 2-2z"/><polyline points="22,6 12,13 2,6"/></svg></a></div></footer></article><article class=post-entry><header class=entry-header><h2>Attention Mechanism</h2></header><div class=entry-content><p>Attention机制 根据OpenAI工程师Andrej Karpathy的讲解视频梳理Attention机制及其在GPT（Generative Pretrained Transformer）语言模型中的应用。在构建GPT的过程中我们会了解到attention的定义和它的工作原理。
构建一个小型GPT模型 GPT属于因果语言模型（Causal Language Models, CLM）。它的任务是根据当前单词（token）预测下一个单词，是自然的无监督任务。比如，现在我们有一个莎士比亚的文本数据：
1 2 3 4 5 6 7 8 First Citizen: Before we proceed any further, hear me speak. All: Speak, speak. First Citizen: You are all resolved rather to die than to famish? 它是由字符组成的，我们需要一个映射，将其转化为模型可接受的数字向量的输入格式。首先将句子进行分词，然后建立词表，再将每个单词映射到词表的索引。这样，我们可以构建GPT的dataloader：对于给定超参数batch_size=$B$，同时给定句子片段长度$T$，dataloader可以定义为从数据中随机采样$B$个连续的长度为$T$的句子片段，来得到一个batch的数据。如下图所示。
接着定义模型架构。这里采用经典的Transformer架构 ( Citation: Vaswani, Shazeer & al., 2017 Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A., Kaiser, L. & Polosukhin, I. (2017). Attention Is All You Need....</p></div><footer class=entry-footer><span title='2023-07-10 14:47:33 +0800 HKT'>July 10, 2023</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;Yue</footer><a class=entry-link aria-label="post link to Attention Mechanism" href=https://yliuhz.github.io/blogs/posts/visofattention/></a></article><article class=post-entry><header class=entry-header><h2>Unsupervised Deep Graph Structure Learning</h2></header><div class=entry-content><p>现实中图的结构可能是不完整或有噪声的。为了在图结构不可靠的情况下较好地完成下游任务，研究者提出了如下的图结构学习算法。
Towards Unsupervised Deep Graph Structure Learning 论文链接： ( Citation: Liu, Zheng & al., 2022 Liu, Y., Zheng, Y., Zhang, D., Chen, H., Peng, H. & Pan, S. (2022). Towards Unsupervised Deep Graph Structure Learning. https://doi.org/10.48550/arXiv.2201.06367 ) 相关工作 - 深度图结构学习 一些传统机器学习算法，如图信号处理，谱聚类，图论等可以解决图结构学习问题。但这类方法往往不能处理图上的高维属性。
最近的深度图结构学习方法用于提升GNN在下游任务上的性能。它们遵循相似的管线：先使用一组可学习的参数建模图的邻接矩阵，再和GNN的参数一起针对下游任务进行优化。基于图结构离散的特性，有多种建模图结构的方法。
概率模型：伯努利概率模型、随机块模型 度量学习：余弦相似度、点积 直接使用$n\times n$的参数矩阵建模邻接矩阵 问题定义 给定输入图$G=(V,E,X)=(A,X)$，$|V|=n,|E|=m,X\in\mathbb{R}^{n\times d}$
结构推理问题：输入信息只有顶点特征矩阵$X$ 结构修改问题：输入信息包含了$A,X$，但$A$可能带有噪声 解决方案 - SUBLIME SUBLIME ( Citation: Liu, Zheng & al., 2022 Liu, Y., Zheng, Y., Zhang, D., Chen, H., Peng, H. & Pan, S. (2022). Towards Unsupervised Deep Graph Structure Learning....</p></div><footer class=entry-footer><span title='2023-06-27 09:59:56 +0800 HKT'>June 27, 2023</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;Yue</footer><a class=entry-link aria-label="post link to Unsupervised Deep Graph Structure Learning" href=https://yliuhz.github.io/blogs/posts/gslearning/></a></article><article class=post-entry><header class=entry-header><h2>Generalization of GNNs and MLPs</h2></header><div class=entry-content><p>本文是 ( Citation: Xu, Zhang & al., 2021 Xu, K., Zhang, M., Li, J., Du, S., Kawarabayashi, K. & Jegelka, S. (2021). How Neural Networks Extrapolate: From Feedforward to Graph Neural Networks. https://doi.org/10.48550/arXiv.2009.11848 ) 的论文解读。OpenReview显示这篇论文是ICLR2021的Oral论文（前5%）。
引言 人类具有泛化性，例如学会算术后可以应用到任意大的数字。对于神经网络而言，前馈网络（也叫多层感知机，MLPs）在学习简单的多项式函数时就不能很好地泛化了。然而，基于MLP的图神经网络（GNNs）却在近期的一些任务上表现出较好的泛化性，包括预测物理系统的演进规律，学习图论算法，解决数学公式等。 粗略地分析可能会觉得神经网络可以在训练分布以外的数据上有任意不确定的表现，但是现实中的神经网络大多是用梯度下降训练的，这就导致其泛化性能有规律可以分析。作者使用"神经切线核"（neural tangent kernel，NTK）工具进行分析。
本文的第一个结论是使用梯度下降训练的MLPs会收敛到任意方向线性的函数，因此MLPs在大多数非线性任务上无法泛化。
接着本文将分析延伸到基于MLP的GNNs，得到第二个结论：使用线性对齐简化目标函数使得基于MLP的GNNs在非线性任务上能够泛化，即将非线性部分提前集成在模型的结构（如GNN的聚合和读出函数）或在输入的表征向量中（使用无监督方法将输入特征转化为表征向量）。
前置知识 设$\mathcal{X}$表示数据（向量或图）的域。任务是学习一个函数$g:\mathcal{X}\to \mathbb{R}$，其中训练数据$\{(\pmb{x}_i,y_i)\}\in\mathcal{D}$，$y_i=g(\pmb{x_i})$，$\mathcal{D}$表示训练数据的分布。在训练数据和测试数据同分布的情况下，$\mathcal{D}=\mathcal{X}$；而在评估泛化能力时，$\mathcal{D} $是$\mathcal{X}$的子集。一个模型的泛化能力可以用泛化误差评估：设$f$为模型在训练数据上得到的函数，$l$为任意损失函数，则泛化误差定义为$\mathbb{E}_{\pmb{x}\sim \mathcal{X} \setminus \mathcal{D}}[l(f(\pmb{x}), g(\pmb{x}))]$
图神经网络GNNs是在MLPs基础上定义的网络。具体来说，初始顶点表征为$\pmb{h}_u^{(0)}=\pmb{x}_u$。在第$k={1..K}$层，顶点表征更新公式为
$$\begin{aligned}\pmb{h}_u^{(k)}&=\sum_{v\in\mathcal{N}(u)}\text{MLP}^{(k)}(\pmb{h}_u^{(k-1)},\pmb{h}_v^{(k-1)},\pmb{w}_{(v,u)}) \\ \pmb{h}_G&=\text{MLP}^{(K+1)}(\sum_{u\in G}\pmb{h}_u^{(K)})\end{aligned}$$
其中$\pmb{h}_u^{(k)}$表示第$k$层GNN输出的顶点$u$的表征，$\pmb{h}_G$表示整张图的表征。$\pmb{h}_u^{(k)}$的计算过程称为聚合，$\pmb{h}_G$的计算过程称为读出。以往研究大多使用$\text{sum}$聚合与$\text{sum}$读出，而本文指出替换为另外的函数能够提升泛化性能。
前馈网络MLPs如何泛化 ReLU MLPs的线性泛化 作者用下图呈现MLPs的泛化方式。灰色表示MLPs要学习的真实函数，蓝色和黑色分别表示模型在训练集和测试集上的预测。可以看到模型可以拟合训练集上的非线性函数，但脱离训练集后迅速变为线性函数。用数字来说，脱离训练集后MLPs预测的决定系数大于$0.99$。
定理1（线性泛化）：假设在NTK机制下使用均方误差训练了一个两层MLP：$f:\mathbb{R}^d\to\mathbb{R}$。对于任意方向$\pmb{v}\in\mathbb{R}^d$，令$\pmb{x}_0=t\pmb{v}$，那么当$t\to\infty$时，$f(\pmb{x}_0+h\pmb{v})-f(\pmb{x}_0)\to\beta_vh$对任意的$h>0$成立，$\beta_v$是常数。进一步地，给定$\epsilon>0$，对于$t=O(\frac{1}{\epsilon})$，$|\frac{f(\pmb{x}_0+h\pmb{v})-f(\pmb{x}_0)}{h}-\beta_v|&lt;\epsilon$。
定理1说明了在训练数据集以外，ReLU MLPs可以拟合几乎线性的函数。对于二次函数（$\pmb{x}^TA\pmb{x}$）、余弦函数($\sum_{i=1}^d\cos(2\pi\cdot\pmb{x}^{(i)})$)、根次函数（$\sum_{i=1}^d\sqrt{\pmb{x}^{(i)}}$）等，ReLU MLPs不能泛化。 在合适的超参数下，MLPs可以正确地泛化L1范数，与定理1一致。如下图所示。
ReLU MLPs什么时候一定（provably）可以泛化 尽管上图显示MLPs对于线性函数可以较好地泛化，但这需要一定的条件，即训练数据集的分布必须足够“多样”。下面的引理1指出只需要$2d$条认真挑选的数据就可以实现ReLU MLPs的线性泛化。
引理1：令$g(\pmb{x})=\pmb{\beta}^T\pmb{x}$表示待拟合的目标函数，$\pmb{\beta}\in\mathbb{R}^d$。假设数据集$\{\pmb{x}_i\}_{i=1}^n$包含正交基$\{\hat{\pmb{x}}_i\}_{i=1}^d$和$\{-\hat{\pmb{x}}_i\}_{i=1}^d$。若使用均方误差在$\{({\pmb{x}}_i,y_i)\}_{i=1}^n$上训练一个两层ReLU MLP，那么$f({\pmb{x}})={\pmb{\beta}}^T{\pmb{x}}$对任意的${\pmb{x}}\in\mathbb{R}^d$成立。
然而，仔细挑选出$2d$条符合条件的样本并不容易。下面的定理2基于更现实的场景，指出只要训练数据的分布包含所有的方向（例如一个包含原点的超球），那么在足够的训练数据量下MLP能够收敛到线性函数。
定理2（泛化的条件）：令$g(\pmb{x})=\pmb{\beta}^T\pmb{x}$表示待拟合的目标函数，$\pmb{\beta}\in\mathbb{R}^d$。假设$\{\pmb{x}_i\}_{i=1}^n$从域$\mathcal{D}$中采样，其中$\mathcal{D}$包含一个连通的子集$S$，满足对任意非零向量$\pmb{w}\in\mathbb{R}^d$，存在$k>0$使得$k\pmb{w}\in S$。若在NTK机制下，使用均方误差在$\{({\pmb{x}}_i,y_i)\}_{i=1}^n$上训练一个两层ReLU MLP，$f(\pmb{x})\xrightarrow{p}\pmb{\beta}^T\pmb{x}$在$n\to\infty$时成立，即$f$依概率收敛到$g$。...</p></div><footer class=entry-footer><span title='2023-06-26 20:08:51 +0800 HKT'>June 26, 2023</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Yue</footer><a class=entry-link aria-label="post link to Generalization of GNNs and MLPs" href=https://yliuhz.github.io/blogs/posts/gnn-ood/></a></article><article class=post-entry><header class=entry-header><h2>Stochastic Blockmodels</h2></header><div class=entry-content><p>本文基于 ( Citation: Karrer & Newman, 2011 Karrer, B. & Newman, M. (2011). Stochastic blockmodels and community structure in networks. Physical Review E, 83(1). 016107. https://doi.org/10.1103/PhysRevE.83.016107 ) 介绍社区发现中经典的随机块模型。 随机块模型是一种生成模型，它建模了社区与图生成之间的联系。尽管简单，随机块模型可以生成非常多样的图结构，包括同配图和异配图。
经典的随机块模型 考虑一个无向的多重图$G$，其中两个顶点之间的连边个数可以超过$1$。令$A_{ij}$表示图的邻接矩阵，当$i\neq j$时$A_{ij}$表示顶点$i$和$j$之间的连边个数，$i=j$时表示自环个数的2倍。 随机块模型假设不同边之间符合独立同泊松分布($P(x=k)=\frac{\lambda^k}{k!}\exp(-\lambda)$，期望为$\lambda$)。令$w_{rs}$表示社区$r$内的顶点和$s$内的顶点之间的期望连边个数，$\frac{1}{2}w_{rr}$表示社区$r$内部顶点之间的期望连边个数。令$g_i$表示顶点$i$的社区标签。拥有上述符号和独立性假设，我们可以写出图$G$的似然函数，即将所有边的存在概率相乘:
$$P(G|w,g)=\prod_{i&lt;j}\frac{(w_{g_ig_j})^{A_{ij}}}{A_{ij}!}\exp(-w_{g_ig_j})\times \prod_i\frac{(\frac{1}{2}w_{g_ig_i})^{A_{ii}/2}}{(A_{ii}/2)!}\exp\left(-\frac{1}{2}w_{g_ig_i}\right)$$
做合并可以得到等价的表达：
$$P(G|w,g)=\frac{1}{\prod_{i&lt;j}A_{ij}!\prod_i2^{A_{ii}/2}(A_{ii}/2)!}\prod_{rs}w_{rs}^{m_{rs}/2}\exp\left(-\frac{1}{2}n_rn_sw_{rs}\right)$$
其中$n_r$表示社区$r$内的顶点个数，$m_{rs}=\sum_{ij}A_{ij}\delta_{g_i,r}\delta_{g_j,s}$表示社区$r$和$s$之间的合计边个数，或者在$r=s$时等于该数值的二倍。
给定观测到的图结构，我们希望$w_{rs}$和$g_i$能够最大化这个似然函数。对似然函数取对数，并忽略掉与$w_{rs}$和$g_i$无关的常数(即前面带有$A_{ij}$的分式)，得到：
$$\log P(G|w,g)=\sum_{rs}(m_{rs}\log w_{rs}-n_rn_sw_{rs})$$
首先对$w_{rs}$求导，$\frac{\partial \log P}{\partial w_{rs}}=\sum_{rs}\left(\frac{m_{rs}}{w_{rs}}-n_rn_s\right)=0$，得到$w$的最优解：
$$\hat{w}_{rs}=\frac{m_{rs}}{n_rn_s},\forall r,s$$
将$\hat{w}_{rs}$带回对数似然，得到$\log P(G|\hat{w},g)=\sum_{rs}m_{rs}\log(m_{rs}/n_rn_s)-2m$，其中$m=\frac{1}{2}\sum_{rs}m_{rs}$表示图中所有连边的个数，与$g_i$无关可以丢掉，因此可以得到最终的对数似然优化目标：
$$\mathcal{L}(G|g)=\sum_{rs}m_{rs}\log\frac{m_{rs}}{n_rn_s}$$
所以，随机块模型定义了一个对数似然。 接下来，我们可以使用各种方法从$K^N$空间中采样$g$，并取使得$\mathcal{L}$最大的$g$作为社区发现的输出。
采样方法（社区发现方法） 方法1 ( Citation: Karrer & Newman, 2011 Karrer, B. & Newman, M. (2011). Stochastic blockmodels and community structure in networks. Physical Review E, 83(1). 016107. https://doi.org/10.1103/PhysRevE.83.016107 ) 中用自然语言描述了采样$g$的方法。首先随机地将图划分为$K$个社区（注意这里假设$K$是已知的）。接下来不断地将顶点移动到另一个使得$\mathcal{L}$增长最大的社区，或者减少最少的社区。当所有顶点移动一次后，检查移动过程中的$\mathcal{L}$值，取对应最大$\mathcal{L}$的移动结果作为下一次循环的开始状态。当$\mathcal{L}$无法被增长时算法停止。作者发现使用不同的随机种子多运行几次取最佳（$\mathcal{L}$最大的结果？）能够得到最好的结果。...</p></div><footer class=entry-footer><span title='2023-06-21 15:58:20 +0800 HKT'>June 21, 2023</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;Yue</footer><a class=entry-link aria-label="post link to Stochastic Blockmodels" href=https://yliuhz.github.io/blogs/posts/sbm/></a></article><article class=post-entry><header class=entry-header><h2>Structural Community Detection</h2></header><div class=entry-content><p>本文专注于解释社区发现的两个经典算法：Louvain方法和Infomap方法。
问题定义 给定一个图$G=(V,E)$，找到一个映射$g:V\to {1,2,\cdots,K}$，$g$将图中的顶点映射到社区标签。
Louvain方法 Louvain方法 ( Citation: Blondel, Guillaume & al., 2008 Blondel, V., Guillaume, J., Lambiotte, R. & Lefebvre, E. (2008). Fast unfolding of communities in large networks. Journal of Statistical Mechanics: Theory and Experiment, 2008(10). P10008. https://doi.org/10.1088/1742-5468/2008/10/P10008 ) 是一种贪心算法，其优化目标是模块度，如下式所示：
$$Q=\frac{1}{2m}\sum_{i,j}\left[A_{ij}-\frac{k_ik_j}{2m}\right]\delta(c_i,c_j)$$
其中$A_{ij}$表示顶点$i$和顶点$j$之间连边的权重；$k_i=\sum_jA_{ij}$表示与顶点$i$相连的边的权重之和；$c_i$表示顶点$i$的社区标签；$\delta(u,v)$在$u=v$时等于1，否则等于0；$m=\frac{1}{2}\sum_{ij}A_{ij}$。
Louvain算法分为两阶段。
初始时设定每个顶点独立属于一个社区 # 第一阶段 生成一个随机的顶点序列Queue For each node i in Queue: For each neighbor j of i: 尝试将i的社区标签c_i修改为j的社区标签c_j 计算模块度的增长DQ If max(DQ)>0: 修改i的社区标签 Else: 保持i的社区标签不变 # 第二阶段 For each community c_i in G: 将社区标签为c_i的所有顶点聚合为一个新的顶点 原c_i内的连边转化为新顶点的自环，边权为原边权之和 原c_i内顶点与另一社区c_j内顶点的所有连边聚合为一条连边，边权为原边权之和 # 重新执行第一阶段，直到模块度Q不再增加 第一阶段中顶点序列的顺序会影响算法的输出。作者发现不同的顶点处理顺序会影响算法的时间效率，但不会对最终的模块度造成过大（significant）的影响。...</p></div><footer class=entry-footer><span title='2023-06-19 10:55:48 +0800 HKT'>June 19, 2023</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Yue</footer><a class=entry-link aria-label="post link to Structural Community Detection" href=https://yliuhz.github.io/blogs/posts/cd/></a></article><footer class=page-footer><nav class=pagination><a class=next href=https://yliuhz.github.io/blogs/page/2/>Next&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2023 <a href=https://yliuhz.github.io/blogs>LIU Yue's blogs</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script type=text/javascript id=clstr_globe src="//clustrmaps.com/globe.js?d=mOVPhw_QyxeNIldDVLiHhU4icnVeTRaMhH8bNjuQ1kk"></script>
<script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>